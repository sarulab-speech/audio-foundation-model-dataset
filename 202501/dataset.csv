label,corpus name,sound type,num channels,sampling rate [kHz],compression,SNR [dB],RT60 [ms],Duration [h],language,license,project page link,download link,,
200drum-machines,200DrumMachines,music,1,44.1,unknown,N/A,N/A,1.2,N/A,unknown,https://www.hexawe.net/mess/200.Drum.Machines/,https://www.hexawe.net/mess/200.Drum.Machines/,,
3d-marco-v.1.0.1,3D Microphone Array Recording Comparison (3D-MARCo),"audio, music, speech",3+,48+,no,N/A,N/A?,0.18,N/A,CC BY-NC 3.0,https://zenodo.org/records/3477602,https://zenodo.org/records/3477602,,
6dof-seld,6DoF SELD: SELD dataset for detecting and localizing sound events from the view of self-motion humans,audio,3+,48+,,"6, 10, 20","120, 300, 410",20.1,N/A,licensed by NTT,https://zenodo.org/records/10473531,https://zenodo.org/records/10473531,,
ace-challenge,ACE CHALLENGE for evaluating state-of-the-art algorithms for blind acoustic parameter estimation from speech,speech,3+,"48+, 16",no,"0, 10, 20 (dev),
-1, 12, 18 (eval)","340, 370, 390, 440, 640, 650, 1250","120 (dev),
eval 4500 utterances for each mic
(時間単位での長さは記載なし)",eng,CC BY-ND 4.0,http://www.ee.ic.ac.uk/naylor/ACEweb/index.html,,,
ace-kising,ACE-KiSing: using singing voice synthesizer for data augmentation,speech,1,48+,no,w/o,w/o,32.5,"eng, cmn",CC BY-NC 4.0,https://huggingface.co/datasets/espnet/ace-kising-segments,https://huggingface.co/datasets/espnet/ace-kising-segments,,
ace-opencpop,ACE-Opencpop: using singing voice synthesizer for data augmentation,speech,1,48+,no,w/o,w/o,129,cmn,CC BY-NC 4.0,https://huggingface.co/datasets/espnet/ace-opencpop-segments,https://huggingface.co/datasets/espnet/ace-opencpop-segments,,
adc2004,ADC2004: Polyphonic Melody Extraction,music,1,44.1,no,w/o,w/o,0.1,N/A,none,http://labrosa.ee.columbia.edu/projects/melody/,http://labrosa.ee.columbia.edu/projects/melody/,,
add2022,ADD: Audio Deep Synthesis Detection Challenge 2022 dataset,speech,1,16,no,w/o,w/o,1000,cmn,CC BY-NC-ND 4.0,http://addchallenge.cn/databases2023,https://zenodo.org/records/12188127,,
add2023,ADD: Audio Deep Synthesis Detection Challenge 2023 dataset,speech,1,16,no,w/o,w/o,740,cmn,CC BY-NC-ND 4.0,http://addchallenge.cn/databases2023,http://addchallenge.cn/downloadADD2023,,
adept,ADEPT: A Dataset for Evaluating Prosody Transfer,speech,1,44.1,no,w/o,w/o,0.2,eng,CC BY 4.0,https://zenodo.org/records/5117102,https://zenodo.org/records/5117102,,
aed,Acoustic Event Dataset: containing 28 class acoustic event sound,audio,1,16,no,N/A,N/A,12.8,eng,various,https://data.vision.ee.ethz.ch/cvl/ae_dataset/,https://data.vision.ee.ethz.ch/cvl/ae_dataset/,,
aishell-1,"Aishell: an open-source Chinese Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd.",speech,1,16,no,w/o,w/o,170,cmn,Apache License v2.0,https://www.openslr.org/33/,https://www.openslr.org/33/,,
aishell-3,"Aishell-3: a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd.",speech,1,44.1,no,w/o,w/o,85,cmn,Apache License v2.0,https://www.openslr.org/93/,https://www.openslr.org/93/,,
aishell-4,Aishell-4: a sizable real-recorded Mandarin speech dataset collected by 8-channel circular microphone array for speech processing in conference scenarios,speech,3+,16,no,w/,w/,120,cmn,CC BY-SA 4.0,https://www.openslr.org/111/,https://www.openslr.org/111/,,
aist-dance-db,AIST Dance Video Database: a shared database containing original street dance videos with copyright-cleared dance music,music,2,44.1,yes,w/,w/,120,N/A,non-commercial,https://aistdancedb.ongaaccel.jp/,https://aistdancedb.ongaaccel.jp/database_download/,,
alimeeting,"A Free Mandarin Multi-channel Meeting Speech Corpus, provided by Alibaba Group",speech,3+,"16, 48+",no,w/,w/,119,cmn,CC BY-SA 4.0,https://www.openslr.org/119/,https://www.openslr.org/119/,,
ami,AMI corpus: a multi-modal data set consisting of 100 hours of meeting recordings,speech,3+,16,no,N/A,N/A,100,eng,CC BY 4.0,https://groups.inf.ed.ac.uk/ami/download/,https://groups.inf.ed.ac.uk/ami/download/,,
aozora,Aozora Bunko furigana-annotated speech corpus,speech,1,22.05,yes,w/,w/,3500,jpn,public domain,https://github.com/ndl-lab/hurigana-speech-corpus-aozoraa,https://github.com/ndl-lab/hurigana-speech-corpus-aozora,,
aragusuku,南琉球新城方言音声データベース (Aragusuku),speech,2,44.1,unknown,w/o,w/,,jpn,research only,https://research.nii.ac.jp/src/Aragusuku.html,https://www.nii.ac.jp/dsc/idr/speech/submit/Aragusuku.html,,
arctic,"CMU ARCTIC: Phonetically balanced, US English single speaker databases designed for unit selection speech synthesis research",speech,1,16,no,w/o,w/o,10,eng,none,http://www.festvox.org/cmu_arctic/,http://www.festvox.org/cmu_arctic/,,
arctic-l2,L2-ARCTIC: a non-native English speech corpus,speech,1,44.1,no,w/o,w/o,27,eng,CC BY-NC 4.0,https://psi.engr.tamu.edu/l2-arctic-corpus/,https://psi.engr.tamu.edu/l2-arctic-corpus/,,
atcosim,ATCOSIM: Air Traffic Control Simulation Speech Corpus,speech,1,32,yes,w/,w/,10,eng,OK for commercial use and re-distribution,https://www.spsc.tugraz.at/databases-and-tools/atcosim-air-traffic-control-simulation-speech-corpus.html,https://www.spsc.tugraz.at/databases-and-tools/atcosim-air-traffic-control-simulation-speech-corpus.html,,
audio-alpaca,Audio-alpaca: a preference dataset for aligning text-to-audio models,audio,1,16,yes,w/,w/,80,eng,Apache License v2.0,https://huggingface.co/datasets/declare-lab/audio-alpacaa,https://huggingface.co/datasets/declare-lab/audio-alpaca,,
audio-dialogues,Audio Dialogues: dialogues dataset for audio and music understanding,audio,1,22.05,yes,w/,w/,440,eng,,https://audiodialogues.github.io/,,,
audio-entailment,AudioEntailment: assessing Deductive Reasoning for Audio Understanding,audio,1,48+,yes,w/,w/,40,eng,MIT,https://github.com/microsoft/AudioEntailment,https://github.com/microsoft/AudioEntailment,,
audio-mnist,audioMNIST: Interpreting and Explaining Deep Neural Networks for Classification of Audio Signals,speech,1,48+,no,w/o,w/o,9.5,eng,MIT,https://github.com/soerenab/AudioMNIST,https://github.com/soerenab/AudioMNIST,,
audiocaps,AudioCaps: Generating Captions for Audios in the Wild,audio,1,48+,yes,w/,w/,2.4,eng,MIT,https://audiocaps.github.io/,https://github.com/cdjkim/audiocaps,,
audiocaps_ja,AudioCaps Japanese,audio,1,48+,yes,w/,w/,2.4,jpn,MIT,https://github.com/sarulab-speech/ml-audiocaps,https://github.com/sarulab-speech/ml-audiocaps,,
audioset,AudioSet: consisting of an expanding ontology of 632 audio event classes,audio,"1, 2",44.1,yes,w/,w/,50,eng,CC BY-SA 4.0,https://research.google.com/audioset/,https://pypi.org/project/audioset-download/,,
audiotime,AudioTime: a strongly aligned audio-text dataset,audio,1,16,yes,w/,w/,14,eng,none,https://github.com/zeyuxie29/AudioTime,https://github.com/zeyuxie29/AudioTime,,
avpd,Amateur vocal percussion dataset: investigating how people with little or no experience in beatboxing approach the task of vocal percussion,"speech, music",1,44.1,no,w/o,w/o,1,N/A,CC BY 4.0,https://zenodo.org/records/5036529,https://zenodo.org/records/5036529,,
awa-lrt,AWA長期間収録音声コーパス (AWA-LTR),speech,1,16,unknown,w/o,w/o,,jpn,research only,https://research.nii.ac.jp/src/AWA-LTR.html,https://www.nii.ac.jp/dsc/idr/speech/submit/AWA-LTR.html,,
bach10-v1.1,bach10 ver1.1the audio recordings of each part and the ensemble of ten pieces of four-part J.S. Bach chorales,music,1,44.1,no,w/o,w/o,0.5,N/A,none,https://github.com/flippy-fyp/Bach10_v1.1,https://github.com/flippy-fyp/Bach10_v1.1,,
baf,BAF: an audio fingerprinting dataset for broadcast monitoring,music,1,8,yes,w/,w/,130,eng,custom (nof for synthesis),https://zenodo.org/records/6868083,https://zenodo.org/records/6868083,,
ballroom,ballroom: many informations on ballroom dancing,music,1,44.1,no,w/o,w/o,6,N/A,none,https://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html,https://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html,,
bats,egyptian fruit bat: An annotated dataset of Egyptian fruit bat vocalizations across varying contexts and during vocal ontogen,audio,1,48+,yes,w/,w/,35,N/A,none,https://www.kaggle.com/datasets/dogukankaggle/fruit-bat-dataset,https://www.kaggle.com/datasets/dogukankaggle/fruit-bat-dataset,,
beans,BEANS: The Benchmark of Animal Sounds,audio,1,"16, 44.1, 48+, others",yes,w/,w/,200,N/A,various,https://github.com/earthspecies/beans,https://github.com/earthspecies/beans,,
beatboxset1,beatboxset1: beatboxing audio data set,speech,1,44.1,no,w/o,w/o,0.1,N/A,CC BY-SA 3.0,https://archive.org/details/beatboxset1,https://archive.org/details/beatboxset1,,
beatport-edm,Beatport EDM key: 1486 two-minute sound excerpts from various EDM subgenres,music,1,44.1,yes,w/,w/,50,N/A,CC BY-SA 4.0,https://zenodo.org/records/1101082,https://zenodo.org/records/1101082,,
beep,"BEEP Dictionary: Phonemic transcriptions of over 250,000 English words. (British English pronunciations)",speech,others,others,unknown,-,-,0,eng,research only,https://www.openslr.org/14/,https://www.openslr.org/14/,,
brid,Brazilian rhythmic instruments dataset: 274 solo and 93 multiple-instrument recorded tracks of 10 different instrument classes with variations playing in 5 main rhythm classes,music,1,44.1,no,N/A,N/A,3,N/A,CC BY 4.0,https://zenodo.org/records/14051323,https://zenodo.org/records/14051323,,
brudex-v2,BRUDEX Database v2: Binaural Room Impulse Responses with Uniformly Distributed External Microphones,audio,3+,48+,no,w/o,3105101300,,eng,MIT,https://zenodo.org/records/8340195,https://zenodo.org/records/8340195,,
bsd10k,"BSD10k: initial version of the Broad Sound Dataset (BSD), a collection of ~10k annotated sounds aligned with the second level of the classes defined in the BST taxonomy",audio,1,44.1,yes,w/,w/,32.5,eng,CC (ファイルごとに違う),https://github.com/allholy/BSD10k?tab=readme-ov-file,https://drive.google.com/file/d/1jyEwyY7TqevOqwMzM1kmWf7gbhrT4Yj0/view,,
buckeye,Buckeye corpus: conversational speech contains high-quality recordings from 40 speakers in Columbus OH conversing freely with an interviewer,speech,,,,,,19,eng,non-commercial,https://buckeyecorpus.osu.edu/,https://buckeyecorpus.osu.edu/,,
but-speech,BUT Speech@FIT Reverb Database,speech,3+,48+,no,w/,w/,78,eng,CC BY 4.0,https://speech.fit.vut.cz/software/but-speech-fit-reverb-database,http://merlin.fit.vutbr.cz/ReverbDB/BUT_ReverbDB_rel_19_06_LibriSpeech-Only.tgz,,
cabank-jp-callfriend,CABank Japanese CallFriend Corpus,speech,2,8,yes,w/,w/,10,jpn,non-commercial,https://ca.talkbank.org/access/CallFriend/jpn.html,https://ca.talkbank.org/access/CallFriend/jpn.html,,
cabank-jp-sakura,CABank Japanese Sakura Corpus,speech,,,,w/,w/,7,jpn,TalkBank license,https://ca.talkbank.org/access/Sakura.html,https://ca.talkbank.org/access/Sakura.html,,
cal500,CAL500,music,1,22.05,yes,w/,w/,3,eng,non-commercial,https://ismir.net/resources/datasets/,http://calab1.ucsd.edu/~datasets/,,
callhome,CALLHOME,speech,2,8,yes,w/,w/,20,"eng, jpn, others",https://www.ldc.upenn.edu/language-resources/data/obtaining,https://huggingface.co/datasets/talkbank/callhome,https://huggingface.co/datasets/talkbank/callhome,,
calls,CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling and Attentive Listening in Customer Center,speech,1,48+,no,w/o,w/o,6.5,jpn,research only,https://sython.org/Corpus/STUDIES-2/,https://www.nii.ac.jp/dsc/idr/speech/submit/STUDIES.html,,
candombe,Candombe dataset,music,2,44.1,no,w/o,w/o,2,N/A,none,https://www.eumus.edu.uy/candombe/datasets/ISMIR2015/,https://www.eumus.edu.uy/candombe/datasets/candombe_dataset.tar.gz,,
captdure,CAPTDURE,audio,"1, 2",48+,no,w/o,w/,1.99,"jpn, eng",CC BY-NC-SA 4.0,https://zenodo.org/records/7965763,https://zenodo.org/records/7965763,,
cbf-v1.2,CBFdataset: A Dataset of Chinese Bamboo Flute Performances,music,1,44.1,no,w/,w/,2.6,cmn,CC BY 4.0,https://zenodo.org/records/5744336,https://zenodo.org/records/5744336,,
cbi,Cornell Bird Identification,audio,1,48+,yes,w/,w/,110,N/A,CC BY-NC-SA 4.0,https://www.kaggle.com/c/birdsong-recognition/data,https://www.kaggle.com/c/birdsong-recognition/data,,
ccmixter,CCMixter,music,2,44.1,yes,w/o,w/o,3,N/A,,https://members.loria.fr/ALiutkus/kam/,https://members.loria.fr/ALiutkus/kam/,,
cejc,Corpus of Everyday Japanese Conversation,speech,others,16,no,w/,N/A,200,jpn,https://www2.ninjal.ac.jp/conversation/cejc/guideline.html#aim,https://www2.ninjal.ac.jp/conversation/cejc.html,https://www2.ninjal.ac.jp/conversation/cejc/contract.html,,
cfad-v4,CFAD dataset v4,speech,1,,no,"0, 5, 10, 15, 20",w/o,,cmn,CC BY 4.0,http://addchallenge.cn/databases2023,https://zenodo.org/records/8122764,,
chcholscene,CochlScene dataset,audio,1,44.1,no,w/,w/,210,N/A,CC BY-SA 3.0,https://zenodo.org/records/7080122,https://zenodo.org/records/7080122,,
chiba3party,千葉大学 3人会話コーパス (Chiba3Party),speech,"2, others",16,unknown,w/,w/,2,jpn,research only,https://chiba3party.jdri.org/,https://www.nii.ac.jp/dsc/idr/speech/submit/Chiba3Party.html,,
chime-1,CHiME-1,speech,2,"16, 48+",no,w/,w/,20,eng,none,https://www.chimechallenge.org/challenges/chime1/index,https://www.myairbridge.com/en/#!/folder/FJTN49Hp1BZgvBLcqnS9LafBpxtbxkHo,,
chime-3,CHiME-3,speech,3+,16,no,w/,N/A,342,eng,https://catalog.ldc.upenn.edu/LDC2017S24,https://www.chimechallenge.org/challenges/chime3/index,https://catalog.ldc.upenn.edu/LDC2017S24,,
chime-6,CHiME-6,speech,3+,16,no,w/,N/A,50,eng,CC BY-SA 4.0,https://www.openslr.org/150/,https://www.openslr.org/150/,,
chopin22,Chopin22,music,2,44.1,yes,w/o,w/,0.8,N/A,none,https://iwk.mdw.ac.at/goebl/mp3.html,https://iwk.mdw.ac.at/goebl/mp3.html,,
choral-singing-v5,Choral Singing Dataset,speech,1,44.1,no,w/o,w/o,2,others,CC BY 4.0,https://zenodo.org/records/2649950,https://zenodo.org/records/2649950,,
choralsynth,ChoralSynth: a synthesized dataset of 20 multitrack choral songs,speech,1,32,yes,w/o,w/o,3.8,"eng, others",CC BY-NC-SA 4.0,https://github.com/MTG/ChoralSynth/tree/main,https://github.com/MTG/ChoralSynth/tree/main,,
chordonomicon,"Chordonomicon: A Dataset of 666,000 Chord Progressions",music,others,others,unknown,,,,N/A,Apache License v2.0,https://github.com/spyroskantarelis/chordonomicon,https://github.com/spyroskantarelis/chordonomicon,,
ciair-vcv,CIAIR Video game Command Voice (CIAIR-VCV),speech,1,16,no,w/,w/,6,jpn,non-commercial,https://research.nii.ac.jp/src/CIAIR-VCV.html,https://www.nii.ac.jp/dsc/idr/speech/submit/CIAIR-VCV.html,,
clarity-21,The First Clarity Enhancement Challenge CEC1,"speech, audio","1, 2",44.1,no,-6 to 6 or 0 to 12,N/A,14,eng,CC BY-SA 4.0,https://claritychallenge.org/docs/cec1/cec1_intro,https://claritychallenge.org/docs/cec1/cec1_download,,
clarity-cec2,The 2nd Clarity Enhancement Challenge,"speech, audio","1, 2",44.1,no,-12 to 6,N/A,,eng,,https://claritychallenge.org/docs/cec2/cec2_intro,https://claritychallenge.org/docs/cec2/cec2_download,,
clarity-cec3,The 3rd Clarity Enhancement Challenge,"speech, audio","1, 2",44.1,no,w/,N/A,,eng,,https://claritychallenge.org/docs/cec3/cec3_intro,https://claritychallenge.org/docs/cec3/cec3_download,,
clarity-cpc1,The 1st Clarity Prediction Challenge,"speech, audio","1, 2",44.1,no,-6 to 6,N/A,,eng,CC BY-SA 4.0,https://claritychallenge.org/docs/cpc1/cpc1_intro,https://claritychallenge.org/docs/cpc1/cpc1_download,,
clarity-icassp2023,The ICASSP 2023 Clarity Challenge,"speech, audio","1, 2",44.1,no,w/,N/A,,eng,,https://claritychallenge.org/docs/icassp2023/icassp2023_intro,https://claritychallenge.org/docs/icassp2023/icassp2023_download,,
closermusicdb,CloserMusicDB: A Modern Multipurpose Dataset of High Quality Music,music,2,44.1,no,w/o,w/o,5,N/A,NC-RCL,https://github.com/closermusic/CloserMusicDB?tab=readme-ov-file,https://zenodo.org/records/13868828,,
clotho-aqa,Clotho-AQA: audio question-answering dataset consisting of 1991 audio samples taken from Clotho dataset,audio,1,44.1,yes,w/,w/,200,eng,"various (audio), MIT (text)",https://zenodo.org/records/6473207,https://zenodo.org/records/6473207,,
clotho-v2.1,Clotho ver.2.1,audio,1,44.1,yes,w/,w/,130,eng,CC BY 4.0,https://zenodo.org/records/4783391,https://zenodo.org/records/4783391,,
cml-tts,CML-TTS: A Multilingual Dataset for Speech Synthesis in Low-Resource Languages,speech,1,24,yes,w/,w/,3176,others,CC BY 4.0,https://www.openslr.org/146/,https://www.openslr.org/146/,,
cn-celeb1-2,CN-Celeb1/2,speech,1,16,yes,w/,w/,274,cmn,CC BY-SA 4.0,https://cnceleb.org/,https://www.openslr.org/82/,,
coconut,coconut: Corpus of Connecting Nihongo Utterance and Text (Coco-Nut),speech,1,24,yes,w/,w/,8,jpn,non-commercial,https://github.com/sarulab-speech/Coco-Nut,https://research.nii.ac.jp/src/en/Coco-Nut.html,,
coconut-humoresque,coconut-humoresque: Who Finds This Voice Attractive? A Large-Scale Experiment Using In-the-Wild Data,speech,1,24,yes,w/,w/,2,jpn,non-commercial,https://github.com/sarulab-speech/Coco-Nut/tree/main/humoresque,https://github.com/sarulab-speech/Coco-Nut/tree/main/humoresque,,
cojads,Corpus of Japanese Dialects,speech,1,8,yes,w/,w/,97,jpn,non-commercial,https://www2.ninjal.ac.jp/cojads/index.html,https://www2.ninjal.ac.jp/cojads/index.html,,
common-crawl-audio,Audio-text pairs extracted from common crawl,audio,"1, 2",others,yes,w/,w/,,"eng, jpn, cmn, others","OK for commercial use, https://commoncrawl.org/terms-of-use",https://github.com/rom1504/cc2dataset,https://github.com/rom1504/cc2dataset,,
common-phone,Common Phone: A Multilingual Dataset for Robust Acoustic Modelling,speech,1,16,yes,w/,w/,116.5,"eng, others",CC0 1.0,https://zenodo.org/records/5846137,https://zenodo.org/records/5846137,,
commonvoice,CommonVoice: A Massively-Multilingual Speech Corpus,speech,1,48+,yes,w/,w/,21000,"eng, jpn, cmn, others",CC0 1.0,https://commonvoice.mozilla.org/,https://commonvoice.mozilla.org/ja/datasets,,
covers80,covers80,music,1,16,yes,w/,w/,5,N/A,none,http://labrosa.ee.columbia.edu/projects/coversongs/covers80/,http://labrosa.ee.columbia.edu/projects/coversongs/covers80/,,
covost,CoVoST: A Large-Scale Multilingual Speech-To-Text Translation Corpus,speech,1,16,yes,w/,w/,600,"eng, jpn, others, cmn",CC0 1.0,https://github.com/facebookresearch/covost,https://github.com/facebookresearch/covost,,
cpjd,CPJD: Crowdsourced Parallel Speech Corpus of Japanese Dialects,speech,1,16,yes,w/,w/,9,jpn,non-commercial,https://sites.google.com/site/shinnosuketakamichi/research-topics/cpjd_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/cpjd_corpus,#REF!,
crema-d,CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset,speech,1,48+,yes,w/,w/,10,eng,ODbL v1.0,https://github.com/CheyneyComputerScience/CREMA-D,https://github.com/CheyneyComputerScience/CREMA-D,,
crowd-uk-ireland,Crowdsourced high-quality UK and Ireland English Dialect speech data set.,speech,1,48+,no,w/,w/,31,eng,CC BY-SA 4.0,https://www.openslr.org/83/,https://www.openslr.org/83/,,
csd,Children's song dataset,"music, speech",1,44.1,no,w/o,w/o,5,"eng, others",CC BY-NC-SA 4.0,https://zenodo.org/records/4916302,https://zenodo.org/records/4916302,,
csibe,Common Sounds in Bedrooms (CSIBE) Corpora,speech,1,44.1,no,w/,w/,2.4,N/A,CC BY 4.0,https://zenodo.org/records/1243714,https://zenodo.org/records/1243714,,
csj,Corpus of Spontaneous Japanese,speech,1,16,no,w/,w/,660,jpn,non-commercial,https://clrd.ninjal.ac.jp/csj/,https://clrd.ninjal.ac.jp/csj/,,
css10,CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages,speech,1,22.05,yes,w/,w/,140,"eng, jpn, others",Apache License v2.0,https://github.com/Kyubyong/css10,https://github.com/Kyubyong/css10,,
ctrsvdd,CtrSVDD: A Benchmark Dataset and Baseline Analysis for Controlled Singing Voice Deepfake Detection,speech,1,16,no,w/o,w/o,150,"jpn, cmn",CC BY-NC 4.0,https://github.com/SVDDChallenge/CtrSVDD2024_Baseline,https://zenodo.org/records/10467648,,
dacci-vodan,DAACI-VoDAn: a dataset for vocal detection that comprises manually-generated vocal activity annotations for 706 full-length music tracks,music,1,44.1,yes,w/,w/,45,eng,CC BY-NC-SA 4.0,https://zenodo.org/records/8017757,https://zenodo.org/records/8017757,,
dagstuhl-chorset-v.1.2.3,Dagstuhl ChoirSet v.1.2.3,speech,"1, 2",22.05,no,w/,w/,1,others,CC BY 4.0,https://www.audiolabs-erlangen.de/resources/MIR/2020-DagstuhlChoirSet,https://zenodo.org/records/4618287,,
dai-onsen,the series of Corpus of Spontaneous Speech in Japanese,speech,"1, 2",48+,no,w/o,w/o,1130,jpn,research only,https://www.timehill.net/asr-mt.htmll,https://www.timehill.net/asr-mt.html,,
dailytalk,DailyTalk: Spoken Dialogue Dataset for Conversational Text-to-Speech,speech,1,22.05,no,w/o,w/o,20,eng,CC BY-SA 4.0,https://github.com/keonlee9420/DailyTalk,https://drive.google.com/drive/folders/1WRt-EprWs-2rmYxoWYT9_13omlhDHcaL,,
damp-vsep,DAMP-VSEP: Smule Digital Archive of Mobile Performances,music,,44.1,yes,w/,w/,95,"eng, others",Smule's Research Data License,https://zenodo.org/records/3553059,https://zenodo.org/records/3553059,,
databaker_zh,DataBaker Chinese Mandarin Female Corpus,speech,1,48+,no,w/o,w/o,12,cmn,non-commercial,https://en.data-baker.com/datasets/freeDatasets/,https://en.data-baker.com/datasets/freeDatasets/,,
dcase2018-task3,DCASE 2018 Task 3 Bird Audio Detection eval set,audio,1,44.1,no,w/,w/,102,N/A,CC BY 4.0,https://dcase.community/challenge2018/task-bird-audio-detection,https://dcase.community/challenge2018/task-bird-audio-detection#development-datasets,,
dcase2021-task05,DCASE 2021 Task 5 Few-shot Bioacoustic Event Detection,audio,1,"8, 22.05, 24, others",no,w/,w/,30,N/A,CC BY 4.0,https://dcase.community/challenge2021/task-few-shot-bioacoustic-event-detection,https://zenodo.org/records/4543504,,
dcase2024-task01,DCASE 2024 Task 1 Data-Efficient Low-Complexity Acoustic Scene Classification,audio,2,44.1,no,w/,w/,64,N/A,non-commercial,https://dcase.community/challenge2024/task-data-efficient-low-complexity-acoustic-scene-classification,https://zenodo.org/records/6337421,,
dcase2024-task02,DCASE 2024 Task 2 Anomalous Sound Detection,audio,1,16,no,w/,w/,18,N/A,CC BY 4.0,"https://zenodo.org/records/11259435, https://zenodo.org/records/11363076","https://zenodo.org/records/11259435, https://zenodo.org/records/11363076",,
dcase2024-task03,"DCASE 2024 Task 3 STARSS23, Development and Evaluation dataset",audio,3+,24,no,w/,w/,10,N/A,MIT,https://dcase.community/challenge2024/task-audio-and-audiovisual-sound-event-localization-and-detection-with-source-distance-estimation,https://zenodo.org/records/7880637,,
dcase2024-task04,DCASE 2024 Task 4 Sound Event Detection with Soft Labels,audio,2,44.1,no,w/,w/,3.1,N/A,non-commercial,https://dcase.community/challenge2023/task-sound-event-detection-with-soft-labels,https://zenodo.org/records/7244360,,
dcase2024-task07,DCASE 2024 Task 7 Sound Scene Synthesis,audio,1,32,yes,w/,w/,0.1,eng,CC BY 4.0,https://dcase.community/challenge2024/task-sound-scene-synthesis,https://zenodo.org/records/10869644,,
dcase2024-task09,DCASE 2024 Task 9 Language-Queried Audio Source Separation | Development Set,audio,1,16,yes,w/,w/,130,eng,CC BY 4.0,https://dcase.community/challenge2024/task-language-queried-audio-source-separation,https://zenodo.org/records/10887496,,
dcase2024-task10,DCASE 2024 Task 10 Acoustic-Based Traffic Monitoring,audio,3+,16,no,N/A,N/A,250,N/A,CC BY-NC-SA 4.0,https://dcase.community/challenge2024/task-acoustic-based-traffic-monitoring,https://zenodo.org/records/10700792,,
deam,DEAM: The MediaEval Database for Emotional Analysis of Music,music,2,44.1,yes,N/A,N/A,23,N/A,CC BY-NC 4.0,https://cvml.unige.ch/databases/DEAM/,https://www.kaggle.com/datasets/imsparsh/deam-mediaeval-dataset-emotional-analysis-in-music,,
debatts,Debatts-Data: The First Madarin Rebuttal Speech Dataset for Expressive Text-to-Speech Synthesis,speech,1,16,no,w/,w/,111,cmn,CC BY-NC 4.0,https://amphionspace.github.io/debatts/,https://huggingface.co/datasets/amphion/Debatts-Data,,
decro-v1.2,deepfake cross-lingual evaluation dataset (DECRO),speech,1,16,no,w/o,w/o,137,"eng, cmn",CC BY 4.0,https://zenodo.org/records/7603208,https://zenodo.org/records/7603208,,
demand,DEMAND: a collection of multi-channel recordings of acoustic noise in diverse environments,audio,3+,"48+, 16",no,N/A,N/A,1.5,N/A,CC BY-SA 3.0,https://inria.hal.science/hal-00796707/en,https://zenodo.org/records/1227121,,
desed,DESED: Domestic environment sound event detection,audio,1,44.1,yes,w/,w/,,N/A,various,https://github.com/turpaultn/DESED,https://github.com/turpaultn/DESED,,
dipco,Dinner Party Corpus,speech,1,16,no,w/,w/,3,eng,CDLA-Permissive,https://www.amazon.science/publications/dipco-dinner-party-corpus,https://huggingface.co/datasets/benjamin-paine/dinner-party-corpus,,
dnr-v2,Divide and Remaster (DnR) v2,"speech, audio, music",1,44.1,yes,w/,w/,55,N/A,CC BY 4.0,https://github.com/darius522/dnr-utils,https://zenodo.org/records/6949108,,
dr-vctk,Device Recorded VCTK: high-quality speech signals recorded in a semi-anechoic chamber using professional audio devices are played back and re-recorded in office environments using relatively inexpensive consumer devices.,speech,1,16,no,w/,w/,18,eng,CC BY 4.0,https://datashare.ed.ac.uk/handle/10283/3038,https://datashare.ed.ac.uk/handle/10283/3038,,
dvtd,"Dresden Vocal Tract Dataset: geometric and (aero)acoustic data of the vocal tract of 22 German speech sounds (16 vowels, 5 fricatives, 1 lateral), each from one male and one female speaker",speech,1,44.1,no,w/,w/,0.1,others,none,https://www.vocaltractlab.de/index.php?page=dvtd,https://www.vocaltractlab.de/index.php?page=dvtd,,
earning-21,Earnings 21: entity dense speech from nine different financial sectors.,speech,1,"others, 44.1, 24, 22.05, 16",yes,w/,w/,39,eng,CC BY-SA 4.0,https://github.com/revdotcom/speech-datasets/tree/main/earnings21,https://codeload.github.com/revdotcom/speech-datasets/zip/refs/heads/main,,
earning-22,Earnings 22 dataset: 119-hour corpus of English-language earnings calls collected from global companies,speech,1,24,yes,w/,w/,119,eng,CC BY-SA 4.0,https://github.com/revdotcom/speech-datasets/tree/main/earnings22,https://github.com/revdotcom/speech-datasets/tree/main/earnings22,,
ears,Expressive Anechoic Recordings of Speech (EARS) dataset,speech,1,48+,no,w/o,w/o,100,eng,CC BY-NC 4.0,https://sp-uhh.github.io/ears_dataset/,https://github.com/facebookresearch/ears_dataset,,
ears-jp,超高齢者音声コーパス (EARS),speech,1,16,no,w/o,w/o,13.4,jpn,research only,https://research.nii.ac.jp/src/EARS.html,https://www.nii.ac.jp/dsc/idr/speech/submit/EARS.html,,
easycom,EasyCom: An Augmented Reality Dataset,speech,"others, 1, 3+",48+,no,w/,645,5,eng,CC BY-NC 4.0,https://github.com/facebookresearch/EasyComDataset,https://github.com/facebookresearch/EasyComDataset/releases,,
edacc,The Edinburgh International Accents of English Corpus,speech,1,32,yes,w/,w/,40,eng,CC BY-SA 2.0,https://groups.inf.ed.ac.uk/edacc/,https://huggingface.co/datasets/edinburghcstr/edacc/discussions,,
edm-cue,EDM-CUE dataset,music,2,44.1,yes,w/,w/,380,"eng, others",MIT,https://huggingface.co/datasets/disco-eth/edm-cue,https://huggingface.co/datasets/disco-eth/edm-cue,,
emilia,"Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation",speech,1,24,yes,w/,w/,101000,"eng, jpn, cmn, others",non-commercial,https://huggingface.co/datasets/amphion/Emilia-Dataset,https://huggingface.co/datasets/amphion/Emilia-Dataset,,
emns,An emotive single-speaker dataset for narrative storytelling,speech,1,48+,no,w/o,w/o,2.3,eng,Apache License v2.0,https://www.openslr.org/136/,https://www.openslr.org/136/,,
emo-soundscapes,Emo-Soudscapes: 1213 6-second Creative Commons licensed audio clips,audio,1,48+,no,N/A,N/A,2,N/A,CC BY 4.0,https://www.metacreation.net/projects/emo-soundscapes/,https://drive.google.com/file/d/1cfMgMssDc-ytedcITvM18nzWcBLeoZFz/view?usp=sharing,,
emofake,EmoFake: An Initial Dataset for Emotion Fake Audio Detection,speech,1,16,no,w/,w/,1.4,"eng, cmn",CC BY-NC-ND 4.0,http://addchallenge.cn/databases2023,https://zenodo.org/records/12806228,,
emotify,Emotify,music,2,44.1,yes,w/,w/,7,N/A,none,https://www.projects.science.uu.nl/memotion/emotifydata/,https://www.projects.science.uu.nl/memotion/emotifydata/,,
emov,EmoV_DB: a database of emotional speech intended to be open-sourced and used for synthesis and generation purpose,speech,1,16,no,w/o,w/o,12,eng,non-commercial,https://www.openslr.org/109/,https://www.openslr.org/115/,,
emovome-v2,Emotional Voice Messages (EMOVOME) database,speech,1,"44.1, 48+",no,w/,w/,5,eng,CC BY 4.0,https://zenodo.org/records/10694370,https://zenodo.org/records/10694370,,
enab,Eastern North American Birds,audio,1,"32, 48+",yes,w/,w/,7,N/A,CC0 1.0,https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.3329#support-information-section,https://esajournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fecy.3329&file=ecy3329-sup-0001-DataS1.zip,,
english-children,Children speech recording,speech,"1, 2",44.1,no,w/,w/,0.5,eng,CC BY 4.0,https://zenodo.org/records/200495,https://zenodo.org/records/200495,,
enst-drums,ENST-Drums,music,2,44.1,yes,w/,w/,1.3,N/A,non-commercial,https://perso.telecom-paristech.fr/grichard/ENST-drums/,https://perso.telecom-paristech.fr/grichard/ENST-drums/,,
epic-sound,EPIC-SOUNDS: a large scale dataset of audio annotations capturing temporal extents and class labels within the audio stream of the egocentric videos from EPIC-KITCHENS-100,audio,1,24,yes,w/,w/,100,N/A,CC BY-NC 4.0,https://epic-kitchens.github.io/epic-sounds/,https://github.com/epic-kitchens/epic-sounds-annotations,,
erkomaishvili,Erkomaishvili Dataset,speech,2,44.1,yes,w/,w/,5,others,none,https://www.audiolabs-erlangen.de/resources/MIR/2019-GeorgianMusic-Erkomaishvili,https://www.audiolabs-erlangen.de/resources/MIR/2019-GeorgianMusic-Erkomaishvili,,
esc50,ESC-50: Dataset for Environmental Sound Classification,audio,1,44.1,yes,w/,w/,5.5,eng,CC BY-NC 4.0,https://github.com/karolpiczak/ESC-50,https://github.com/karolpiczak/ESC-50,,
esc50-voice,ESC-50-Voice: Dataset of vocal imitation for environmental sound in ESC-50,speech,1,48+,no,w/o,w/o,40,N/A,none,https://zenodo.org/records/11385662,https://zenodo.org/records/11385662,,
esd,Emotional Speech Dataset for Speech Synthesis and Voice Conversion,speech,1,16,no,w/,w/,29,"eng, cmn",https://drive.google.com/file/d/1Q1Wa45u-ymzpUO3_U-y8yisn4f5PlDIK/view,https://github.com/HLTSingapore/Emotional-Speech-Data,https://drive.google.com/file/d/1scuFwqh8s7KIYAfZW1Eu6088ZAK2SI-v/view,,
fakeavceleb,FakeAVCeleb: containing not only deepfake videos but also respective synthesized lip-synced fake audios.,speech,1,16,yes,w/,w/,43,eng,non-commercial,https://sites.google.com/view/fakeavcelebdash-lab/,https://sites.google.com/view/fakeavcelebdash-lab/download?authuser=0,,
fleurs,FLEURS: the speech version of the FLoRes machine translation benchmark,speech,1,16,yes,w/,w/,1400,"eng, jpn, cmn, others",CC BY 4.0,https://huggingface.co/datasets/google/fleurs,https://huggingface.co/datasets/google/fleurs,,
fma,Free Music Archive (FMA): Royalty-free music for your videos,music,2,"44.1, others",yes,w/,w/,8232,N/A,Creative Commons-licensed,https://www.epidemicsound.com/license/royalty-free-music/?_us=adwords&_usx=17450052410_free%20music%20archive&utm_source=google&utm_medium=paidsearch&utm_campaign=17450052410&utm_term=free%20music%20archive&gad_source=1&gclid=Cj0KCQiArby5BhCDARIsAIJvjISOxdezCnNdKMwcO0BmbPylU4x1TcbCpAgHnLbosGCSWf4BsMu1zDIaAiAJEALw_wcB,https://os.unil.cloud.switch.ch/fma/fma_full.zip,,
free-st,"Free ST American English Corpus: A free American English corpus by Surfingtech (www.surfing.ai), containing utterances from 10 speakers, Each speaker has about 350 utterances",speech,1,16,yes,w/,w/,5,eng,CC BY-NC-ND 4.0,https://www.openslr.org/45/,https://www.openslr.org/45/,,
fsd50k,"FSD50K: an open dataset of human-labeled sound events containing 51,197 Freesound clips unequally distributed in 200 classes drawn from the AudioSet Ontology",audio,1,16,yes,w/,w/,108,N/A,CC (various),https://zenodo.org/records/4060432,https://zenodo.org/records/4060432,,
german-own-voice,German own voice recordings with hearable microphones,speech,3+,44.1,no,w/,w/,4.5,others,CC BY-NC-ND 4.0,https://zenodo.org/records/10844599,https://zenodo.org/records/10844599,,
gib,Hainan gibbon calls,audio,1,others,no,w/,w/,10,others,CC BY-NC-SA 4.0,https://zenodo.org/records/6328319,https://zenodo.org/records/6328319,,
giga-s2s,GigaS2S: Large Scale English-to-X Speech-to-Speech Translation,speech,1,16,yes,"w/, w/o","w/, w/o",9000,"eng, cmn",CC BY 4.0,https://github.com/SpeechTranslation/GigaS2S,https://github.com/SpeechTranslation/GigaS2S?tab=readme-ov-file,,
giga-st,GigaST,speech,1,16,yes,w/,w/,10000,"eng, others",CC BY-NC 4.0,https://st-benchmark.github.io/resources/GigaST.html,https://st-benchmark.github.io/resources/GigaST.html#download,,
gigaspeech,"an evolving, multi-domain English speech recognition corpus with 10,000 hours of high quality labeled audio suitable for supervised training.",speech,1,16,yes,w/,w/,10000,eng,non-commercial,https://huggingface.co/datasets/speechcolab/gigaspeech,https://huggingface.co/datasets/speechcolab/gigaspeech,,
goodsounds,GoodSounds: monophonic recordings of two kind of exercises: single notes and scales,music,1,48+,no,w/o,w/o,28,N/A,CC BY 4.0,https://www.upf.edu/web/mtg/good-sounds,https://zenodo.org/records/4588740#.YFDoDdyCFPY,,
grid,The Grid Audio-Visual Speech Corpus,speech,1,others,no,w/o,w/o,0.5,eng,CC BY 4.0,https://zenodo.org/records/3625687,https://zenodo.org/records/3625687,,
gsr-jd,"Regional Difference in Spoken Japanese Dialects"" Spoken Japanese Dialect Corpus",speech,1,16,no,w/o,N/A,145,jpn,research only,https://research.nii.ac.jp/src/GSR-JD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/GSR-JD.html,,
gtsinger,GTSinger,"speech, music",1,48+,no,w/o,w/o,81,others,CC BY-NC-SA 4.0,https://gtsinger.github.io/home,https://huggingface.co/datasets/GTSinger/GTSinger,,
gtzan,GTZAN: Music Genre Classification,music,1,22.05,no,w/,w/,8,N/A,none,https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification,https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification,,
guitarduet,GuitarDuets Dataset,music,2,44.1,no,w/o,w/o,3,N/A,CC BY 4.0,https://zenodo.org/records/12802440,https://zenodo.org/records/12802440,,
guitarset,GuitarSet,music,3+,44.1,no,w/o,w/o,3,N/A,CC BY 4.0,https://guitarset.weebly.com/,https://zenodo.org/records/3371780,,
half-truth,Half-Truth,speech,1,44.1,no,w/o,w/o,60,cmn,CC BY 4.0,http://addchallenge.cn/databases2023,https://zenodo.org/records/10377492,,
hbdb,HumBugDB,audio,1,"8, 44.1",no,w/,w/,20,N/A,CC BY 4.0,https://github.com/HumBug-Mosquito/HumBugDB,https://zenodo.org/records/4904800,,
hcudb,感情音声コーパス (HCUDB),speech,1,48+,unknown,w/o,w/o,,jpn,research only,https://research.nii.ac.jp/src/HCUDB.html,https://www.nii.ac.jp/dsc/idr/speech/submit/HCUDB.html,,
hi-mia-cw,A Free Mandarin Supplemental Speech Corpus to HI-MIA Database,speech,1,16,no,w/,w/,6,"eng, cmn",CC BY-SA 4.0,https://openslr.magicdatatech.com/120/,https://openslr.magicdatatech.com/120/,,
hifi-tts,Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS),speech,1,44.1,unknown,w/,w/,292,eng,CC BY 4.0,https://www.openslr.org/109/,https://www.openslr.org/109/,,
honburg,homburg,music,2,44.1,yes,w/o,w/o,5,N/A,none,https://www-ai.cs.tu-dortmund.de/audio.html,https://www-ai.cs.tu-dortmund.de/audio.html,,
icassp2023-dns,ICASSP 2023 Deep Noise Suppression Challenge,"speech, audio",1,48+,yes,w/,w/,760,"eng, cmn","various (https://opensource.microsoft.com/cla/,)",https://github.com/microsoft/DNS-Challenge?tab=readme-ov-file,https://github.com/microsoft/DNS-Challenge?tab=readme-ov-file,,
icassp2024-icmc-asr,ICASSP 2024 ICMC-ASR Grand Challenge dataset,speech,3+,,no,w/,w/,1400,cmn,none,https://icmcasr.org/,https://icmcasr.org/,,
idmt-smt-bass,IDMT-SMT-Bass,music,1,44.1,no,w/o,w/o,3.6,N/A,CC BY-NC-ND 4.0,https://www.idmt.fraunhofer.de/en/publications/datasets/bass.html,https://zenodo.org/records/7188892,,
idmt-smt-bass-single,IDMT-SMT-Bass-SINGLE-TRACK,music,1,44.1,no,w/o,w/o,0.1,N/A,CC BY-NC-ND 4.0,https://www.idmt.fraunhofer.de/en/publications/datasets/bass_lines.html,https://zenodo.org/records/7544099,,
idmt-smt-drum,IDMT-SMT-Drum,music,1,44.1,no,w/o,w/o,2.1,N/A,CC BY-NC-ND 4.0.,https://www.idmt.fraunhofer.de/en/publications/datasets/drums.html,https://zenodo.org/records/7544164,,
idmt-smt-effect,IDMT-SMT-Audio-Effects,music,1,44.1,no,w/o,w/o,30,N/A,CC BY-NC-ND 4.0.,https://www.idmt.fraunhofer.de/en/publications/datasets/audio_effects.html,https://zenodo.org/records/7544032,,
idmt-smt-guitar,IDMT-SMT-Guitar,music,1,44.1,no,w/o,w/o,,N/A,CC BY-NC-ND 4.0.,https://www.idmt.fraunhofer.de/en/publications/datasets/guitar.html,https://zenodo.org/records/7544110,,
imad-ds,IMAD-DS: A Dataset for Industrial Multi-Sensor Anomaly Detection Under Domain Shift Conditions,audio,1,16,no,w/,w/,,N/A,CC BY-SA 4.0,https://github.com/augustif/IMAD-DS_baseline,https://zenodo.org/records/12665499,,
ir-br-tf,Database of multichannel in-ear and behind-the-ear head-related and binaural room impulse responses,audio,3+,48+,unknown,w/o,"0, 300, 900, 1250",1,others,research or education only,https://medi.uni-oldenburg.de/hrir/,https://medi.uni-oldenburg.de/hrir/html/download.html,,
irmas,IRMAS: a dataset for instrument recognition in musical audio signals,music,,,,,,,,CC BY-NC-SA 4.0,https://www.upf.edu/web/mtg/irmas,https://zenodo.org/records/1290750#.WzCwSRyxXMU,,
ita,ITA: Inter-field Task Accelerating corpus,speech,1,48+,no,w/o,w/o,2,jpn,non-commercial,https://github.com/mmorise/ita-corpus,https://zunko.jp/multimodal_dev/login.php,,
ita-third-party,ITA third-pirty,speech,1,48+,no,w/o,w/o,5,jpn,non-commercial,https://github.com/mmorise/ita-corpus,https://tyc.rei-yumesaki.net/material/corpus/ita-list/,,
jacappella,jaCappella: A Japanese a Cappella Vocal Ensemble Corpus,music,1,48+,no,w/o,w/o,0.5,jpn,Research (free)+Commercial (chargeable),https://huggingface.co/datasets/jaCappella/jaCappella,https://huggingface.co/datasets/jaCappella/jaCappella,,
jchat,J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling,speech,1,22.05,yes,w/,w/,69000,jpn,CC BY-NC 4.0,https://huggingface.co/datasets/sarulab-speech/J-CHAT,https://huggingface.co/datasets/sarulab-speech/J-CHAT,,
jingju-a-cappella-v7,Jingju a cappella singing dataset part1,speech,"1, 2",44.1,no,w/o,w/o,1,cmn,CC BY-NC 4.0,https://zenodo.org/records/1323561,https://zenodo.org/records/13235611,,
jlcorpus,JL-Corpus: Emotional speech corpus with primary and secondary emotions,speech,1,44.1,no,w/o,w/o,1,others,CC0 1.0,https://github.com/tli725/JL-Corpus?tab=readme-ov-file,https://www.kaggle.com/datasets/tli725/jl-corpus?resource=download,,
jspaw,"J-SpAW: Japanese corpus for speaker verification and spoofing attack detection, recorded in the wild",speech,1,48+,yes,w/,w/,4,jpn,research only,https://github.com/takamichi-lab/j-spaw,https://github.com/takamichi-lab/j-spaw,,
jsss,JSSS: Japanese speech corpus for summarization and simplification,speech,1,24,no,w/o,w/o,8,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/research-topics/jsss_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/jsss_corpus,,
jsut,JSUTコーパス,speech,1,48+,no,w/o,w/o,10,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/publication/jsut,https://drive.google.com/file/d/1f7bIQfwWdFOxeaYzs5Cw-HTcA8uwQ8qp/view,,
jsut-book,JSUT-book: JSUT audiobook reading corpus,speech,1,48+,no,w/o,w/o,1,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song,,
jsut-song,JSUT-song corpus: JSUT singing voice corpus,speech,1,48+,no,w/o,w/o,0.5,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song,,
jsut-vi,JSUT vi: JSUT vocal imitation corpus,"speech, audio",1,48+,no,w/o,w/o,0.5,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-vi,https://sites.google.com/site/shinnosuketakamichi/publication/jsut-vi,,
jtubespeech,jTubeSpeech: Corpus of Japanese speech collected from YouTube,speech,1,16,yes,w/,w/,1200,jpn,research only,https://github.com/sarulab-speech/jtubespeech,,,
jtubespeech-asv,JTubeSpeech-ASV: Japanese speech corpus for automatic speaker verification,speech,1,16,yes,w/,w/,484,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/research-topics/jtubespeech-asv_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/jtubespeech-asv_corpus,,
jvnv,JVNV: Japanese emotional speech corpus with Verbal content and Nonverbal Vocalizations,speech,1,48+,no,w/o,w/o,4,jpn,CC BY-SA 4.0,https://sites.google.com/site/shinnosuketakamichi/research-topics/jvnv_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/jvnv_corpus,,
jvpd,身体情報付き男・女・子どもの母音音声データベース (JVPD),speech,1,16,unknown,both,w/,0.1,jpn,research only,https://research.nii.ac.jp/src/JVPD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/JVPD.html,,
jvs-third-party,JVS third-pirty,speech,1,48+,no,w/o,w/o,5,jpn,various,https://tyc.rei-yumesaki.net/material/corpus/voiceactress100/list/,https://tyc.rei-yumesaki.net/material/corpus/voiceactress100/list/,,
jwc,児童の単語音声データベース (JWC),speech,1,16,unknown,w/o,w/o,,jpn,research only,https://research.nii.ac.jp/src/JWC.html,https://www.nii.ac.jp/dsc/idr/speech/submit/JWC.html,,
kaggle-birdclef-2023,BirdCLEF 2023: Identify bird calls in soundscapes,audio,1,32,yes,w/,w/,0.5,N/A,kaggle,https://www.kaggle.com/competitions/birdclef-2023/data,https://www.kaggle.com/competitions/birdclef-2023/data,,
kaggle-birds-2022,Sound Of 114 Species Of Birds Till 2022,audio,1,44.1,yes,w/,w/,2,N/A,CC0 1.0,https://www.kaggle.com/datasets/soumendraprasad/sound-of-114-species-of-birds-till-2022?select=Voice+of+Birds,https://www.kaggle.com/datasets/soumendraprasad/sound-of-114-species-of-birds-till-2022?select=Voice+of+Birds,,
kaggle-birdsong,birdsong resampled train audio,audio,1,32,yes,w/,w/,32,N/A,various,https://www.kaggle.com/datasets/ttahara/birdsong-resampled-train-audio-00,https://www.kaggle.com/datasets/ttahara/birdsong-resampled-train-audio-00,,
kaggle-cat-meow,Cat Meow Classification,audio,1,8,yes,w/,w/,0.1,N/A,CC BY-NC 4.0,https://www.kaggle.com/datasets/andrewmvd/cat-meow-classification/data,https://www.kaggle.com/datasets/andrewmvd/cat-meow-classification/data,,
kaggle-cats-dongs,Audio Cats and Dogs: Classify raw sound events,audio,1,16,yes,w/,w/,0.5,N/A,CC BY-SA 3.0,https://www.kaggle.com/datasets/mmoreaux/audio-cats-and-dogs,https://www.kaggle.com/datasets/mmoreaux/audio-cats-and-dogs,,
kaggle-emergency-siren,Emergency Vehicle Siren Sounds: Collection of 3-second long wav-format of Emergency Vehicle Sounds,audio,2,44.1,no,w/,w/,0.5,N/A,OK for commercial use,https://www.kaggle.com/datasets/vishnu0399/emergency-vehicle-siren-sounds,https://www.kaggle.com/datasets/vishnu0399/emergency-vehicle-siren-sounds,,
kaggle-heartbeat,Heartbeat Sounds: Classifying heartbeat anomalies from stethoscope audio,audio,1,44.1,no,w/,w/,1,N/A,CC0 1.0,https://www.kaggle.com/datasets/kinguistics/heartbeat-sounds,https://www.kaggle.com/datasets/kinguistics/heartbeat-sounds,,
kaggle-human-screaming,Human Screaming Detection Dataset: A dataset for audio classification for emergency detection,speech,2,44.1,no,w/,w/,6,N/A,MIT,https://www.kaggle.com/datasets/whats2000/human-screaming-detection-dataset,https://www.kaggle.com/datasets/whats2000/human-screaming-detection-dataset,,
kaggle-infant-cry,Infant cry audio corpus: An infant cry audio corpus that has been built through the Donate-a-cry campaign,speech,1,8,no,w/,w/,1,N/A,ODbL v1.0,https://www.kaggle.com/datasets/warcoder/infant-cry-audio-corpus,https://www.kaggle.com/datasets/warcoder/infant-cry-audio-corpus,,
kaggle-respiratory,Respiratory Sound Database: Use audio recordings to detect respiratory diseases.,audio,1,44.1,no,w/,w/,5.5,N/A,unknown,https://www.kaggle.com/datasets/vbookshelf/respiratory-sound-database,https://www.kaggle.com/datasets/vbookshelf/respiratory-sound-database,,
kaggle-speech-sentiment,Audio Speech Sentiment,speech,2,44.1,no,w/,w/,0.2,eng,CC0 1.0,https://kaggle.com/datasets/imsparsh/audio-speech-sentiment,https://kaggle.com/datasets/imsparsh/audio-speech-sentiment,,
kaggle-summarization,Audio Summarization: Dataset with audio and texts for the audio summarization or speech-to-text tasks,speech,2,44.1,yes,w/o,w/o,2,eng,CC BY-NC-SA 3.0,https://www.kaggle.com/datasets/nfedorov/audio-summarization,https://www.kaggle.com/datasets/nfedorov/audio-summarization,,
kaggle-xqc,xqc-audio-clips: 69 audio clips of XQC live streams,speech,2,44.1,yes,w/,w/,100,eng,DbCL v1.0,https://www.kaggle.com/datasets/naklecha/xqcaudioclips,https://www.kaggle.com/datasets/naklecha/xqcaudioclips,,
keio-esd,慶應義塾大学 研究用感情音声データベース (Keio-ESD),speech,1,16,unknown,w/o,w/o,0.2,jpn,research only,https://research.nii.ac.jp/src/Keio-ESD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/Keio-ESD.html,,
kespeech,KeSpeech: An Open Source Speech Dataset of Mandarin and Its Eight Subdialects,speech,1,16,no,w/,w/,1542,cmn,non-commercial,https://github.com/KeSpeech/KeSpeech,https://github.com/KeSpeech/KeSpeech,,
koniwa,Koniwa,speech,1,others,yes,w/,w/,150,jpn,CC BY 4.0 など,https://github.com/koniwa/koniwa,https://drive.google.com/drive/folders/1edUnYJpT8y0ZmAQSE_fJPQ6VnNBS6qWA,,
kujc,日中対照調音動態MRI動画コーパス (KUJC-MRI),"speech, others",2,44.1,no,w/,w,,jpn,research only,https://research.nii.ac.jp/src/KUJC-MRI.html,https://www.nii.ac.jp/dsc/idr/speech/submit/KUJC-MRI.html,,
laion-audio-630k,LAION-Audio-630K Freesound Dataset,audio,1,48+,yes,w/,w/,4325,N/A,none,https://huggingface.co/datasets/Meranti/CLAP_freesound,https://huggingface.co/datasets/Meranti/CLAP_freesound,,
laughterscape,Laughterscape,speech,1,24,yes,w/,w/,6,jpn,research only,https://sites.google.com/site/shinnosuketakamichi/research-topics/laughter_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/laughter_corpus,,
libricss,LibriCSS: handling overlapped speech in conversational audio signals,speech,3+,16,yes,w/,w/,10,eng,MIT,https://github.com/chenzhuo1011/libri_css,https://github.com/chenzhuo1011/libri_css,,
librilight,LibriLight,speech,1,16,yes,w/,w/,60000,eng,CC BY 4.0,https://github.com/facebookresearch/libri-light,https://github.com/facebookresearch/libri-light/blob/main/data_preparation/README.md,,
librimix,Libri-Mixed-Speakers,speech,1,16,yes,w/,w/,6,eng,CC BY-SA 3.0,https://www.openslr.org/135/,https://www.openslr.org/135/,,
librispeech,LibriSpeech,speech,1,16,yes,w/,w/,960,eng,CC BY 4.0,https://www.openslr.org/12,https://www.openslr.org/12,,
librispeech-d,Librispeech diarization,speech,1,16,no,w/,w/,90,eng,CC BY 4.0,https://github.com/EMRAI/emrai-synthetic-diarization-corpus,https://github.com/EMRAI/emrai-synthetic-diarization-corpus,,
libritts,LibriTTS ,speech,1,24,yes,w/,w/,585,eng,CC BY 4.0,https://openslr.org/60/,https://openslr.org/60/,,
libritts-p,LibriTTS-P,speech,1,24,no,w/o,w/o,585,eng,CC BY 4.0,https://github.com/line/LibriTTS-P,https://github.com/line/LibriTTS-P,,
libritts-r,LibriTTS-R,speech,1,24,no,w/o,w/o,585,eng,CC BY 4.0,https://www.openslr.org/141/,https://www.openslr.org/141/,,
ljspeech,LJspeech,speech,1,24,yes,w/,w/,24,eng,public domain,https://keithito.com/LJ-Speech-Dataset/,https://keithito.com/LJ-Speech-Dataset/,,
lm-ssd,A Dataset of Larynx Microphone Recordings for Singing Voice Reconstruction,"speech, music",1,44.1,no,w/,w/,20,eng,CC BY 4.0 (but songs are commercial),https://audiolabs-erlangen.de/resources/MIR/LM-SVR/,https://audiolabs-erlangen.de/content/resources/MIR/LM-SVR/lm-ssd.zip,,
locata,Acoustic Source Localization and Tracking (LOCATA),audio,3+,48+,no,w/,about 550,0.9,eng,ODC-By v1.0,https://zenodo.org/records/3630471,https://zenodo.org/records/3630471,,
lp-musiccaps,LP-MusicCaps: LLM-Based Pseudo Music Captioning,music,,,yes,w/,w/,15,eng,MIT,https://github.com/seungheondoh/lp-music-caps/tree/main,https://huggingface.co/datasets/seungheondoh/LP-MusicCaps-MSD,,
lp-musicmtt,LPMusicMTT,music,,,yes,w/,w/,60,eng,MIT,https://huggingface.co/datasets/seungheondoh/LP-MusicCaps-MTT,https://huggingface.co/datasets/seungheondoh/LP-MusicCaps-MTT,,
LRW1-2-3,Lip Reading Datasets,speech,1,16,yes,w/,w/,800,eng,non-commercial,https://www.robots.ox.ac.uk/~vgg/data/lip_reading/,https://www.robots.ox.ac.uk/~vgg/data/lip_reading/,,
lsx,Librispeech Slakh Unmix (LSX),"music, speech",1,16,yes,w/,w/,30,eng,CC BY 4.0,https://zenodo.org/records/7765140,https://zenodo.org/records/7765140,,
m-tedx,Multilingual TEDx,speech,2,44.1,yes,w/,w/,760,"eng, others",CC BY-NC-ND 4.0,https://openslr.org/100,https://openslr.org/100,,
m4singer,"M4Singer: A Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus","music, speech",1,44.1,no,w/o,w/o,29.77,"cmn, others",CC BY-NC-SA 4.0,https://github.com/M4Singer/M4Singer?tab=readme-ov-file,https://drive.google.com/file/d/1xC37E59EWRRFFLdG3aJkVqwtLDgtFNqW/view,,
macs,MACS: Multi-Annotator Captioned Soundscapes,audio,2,48+,yes,w/,w/,40,eng,non-commercial,https://researchportal.tuni.fi/en/datasets/macs-multi-annotator-captioned-soundscapes,https://zenodo.org/records/5114771,,
maestro-v3,Maestro-v3.0.0: a dataset composed of about 200 hours of virtuosic piano performances captured with fine alignment (~3 ms) between note labels and audio waveforms.,music,2,"44.1, 48+",no,w/o,w/o,200,N/A,CC BY-NC-SA 4.0,https://magenta.tensorflow.org/datasets/maestro#v300,https://magenta.tensorflow.org/datasets/maestro#v300,,
magicdata,MAGICDATA Mandarin Chinese Read Speech Corpus,speech,1,16,yes,w/,w/,755,cmn,CC BY-NC-ND 4.0,https://www.openslr.org/68,https://www.openslr.org/68,,
magnatagatune,"MagnaTagATune: corpus by Magic Data Technology Co., Ltd. , containing 755 hours of scripted read speech data from 1080 native speakers of the Mandarin Chinese spoken in mainland China",music,1,16,yes,w/o,w/o,200,"eng, cmn",CC BY-NC-SA 1.0,https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset,https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset,,
massive-dma,Massive Distributed Microphone Array Dataset,speech,3+,48+,no,w/o,780,4,eng,CC BY 4.0,https://publish.illinois.edu/augmentedlistening/massive-distributed-microphone-array-dataset/,https://databank.illinois.edu/datasets/IDB-6216881,,
mast-rhythm-v1.1,MAST-Rhythm: collection of 3721 audio files cropped from recordings of conservatory entrance examinations in Turkey,music,1,44.1,yes,w/o,w/o,5,N/A,CC BY 4.0,https://zenodo.org/records/2620357,https://zenodo.org/records/2620357,,
mdcc,Automatic Speech Recognition Datasets in Cantonese,speech,1,16,yes,w/,w/,74,others,research only,https://github.com/HLTCHKUST/cantonese-asr,https://drive.google.com/file/d/1epfYMMhXdBKA6nxPgUugb2Uj4DllSxkn/view,,
medley-solos-db-v1.2,Medley-solos-DB: a cross-collection dataset for musical instrument recognition,music,1,44.1,no,w/o,w/o,17,N/A,CC BY 4.0,https://zenodo.org/records/3464194,https://zenodo.org/records/3464194,,
medleydb-v2,Medley DB v2.0,music,2,44.1,no,w/o,w/o,8,N/A,CC BY-NC-SA 4.0,https://medleydb.weebly.com/,https://zenodo.org/records/1715175#.XAzIzxNKjyw,,
mer500,"MER500: songs in 5 popular emotional categories for Hindi film songs as Romantic, Happy, Sad, Devotional and Party",music,2,44.1,no,w/o,w/o,1.3,N/A,unknown,https://www.kaggle.com/datasets/makvel/mer500?select=Happy,https://www.kaggle.com/datasets/makvel/mer500?select=Happy,,
mimii,MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection,audio,3+,16,no,w/,w/,90,N/A,CC BY-SA 4.0,https://zenodo.org/records/3384388,https://zenodo.org/records/3384388,,
mimii-dg,MIMII DG: Sound Dataset for Malfunctioning Industrial Machine Investigation for Domain Generalization Task,audio,1,16,no,w/,w/,50,N/A,CC BY-NC-SA 4.0,https://zenodo.org/records/6529888,https://zenodo.org/records/6529888,,
mir-1k,MIR-1K,music,2,16,no,w/o,w/o,6,N/A,none,http://mirlab.org/dataset/public/,http://mirlab.org/dataset/public/,,
mls,Multilingual LibriSpeech (MLS),speech,1,16,no,w/,w/,50000,"eng, others",CC BY 4.0,https://www.openslr.org/94/,https://www.openslr.org/94/,,
mmau,MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark,"speech, audio, music",,,,,,,eng,none,https://sakshi113.github.io/mmau_homepage/,https://github.com/Sakshi113/mmau/tree/main?tab=readme-ov-file,,
mms,MMS-unlab v2,speech,1,16,yes,w/,w/,8900,"eng, jpn, cmn, others",CC BY-NC 4.0,https://huggingface.co/datasets/espnet/mms_ulab_v2,https://huggingface.co/datasets/espnet/mms_ulab_v2,,
mobvoi-hotwords,Chinese hotwords detection dataset,speech,1,16,yes,w/,w/,262,cmn,Apache License v2.0,https://www.openslr.org/87/,https://www.openslr.org/87/,,
moisesdb,MoisesDB,music,2,44.1,unknown,,,14,,NC-RCL,https://music.ai/research/#datasets,https://music.ai/research/#datasets,,
mos-bench,MOS-Bench,speech,1,"16, 24, 48+, 22.05",no,"w/, w/o","w/, w/o",,"eng, jpn, cmn, others",https://github.com/unilight/sheet,https://github.com/unilight/sheet,https://github.com/unilight/sheet,,
mosel,MOSEL: multilingual dataset collection including up to 950K hours of open-source speech recordings,speech,1,,unknown,w/,w/,950000,"eng, others",CC BY 4.0,https://mt.fbk.eu/mosel/,https://huggingface.co/datasets/FBK-MT/mosel,,
msd,Million Song Dataset (MSD),music,,,,,,,,,,,,
msd100,MSD100: Mixing Secret Dataset 100,music,"1, 2",44.1,no,N/A,N/A,7,,https://www.multitracks.com/terms/,https://sisec.inria.fr/sisec-2015/,https://sisec.inria.fr/sisec-2015/2015-professionally-produced-music-recordings/,,
mtd,A Multimodal Dataset of Musical Themes for MIR Research,music,2,44.1,unknown,w/o,N/A,5,N/A,CC BY 4.0,https://www.audiolabs-erlangen.de/resources/MIR/MTDD,https://www.audiolabs-erlangen.de/resources/MIR/MTD,,
mtg-jamendo,MTG-Jamendo,music,2,44.1,yes,w/o,w/o,3777,N/A,曲依存,https://mtg.github.io/mtg-jamendo-dataset/,https://mtg.github.io/mtg-jamendo-dataset/,,
mtg-query,MTG-Query by Humming,music,1,44.1,unknown,w/o,w/o,0.88,N/A,"The MTG-QBH dataset is offered free of charge for internal non-commercial use only.  You may not redistribute, publically communicate or modify it, unless expressly permitted by the Universitat Pompeu Fabra (UPF) or by applicable law. The individual contents of the dataset may be protected by copyright, and a non-transferrable limited license to reproduce and use the same is granted for the indicated purpose only.",https://www.upf.edu/web/mtg/mtg-qbh,https://zenodo.org/records/1290712#.WzSxrxyxXMU,,
muchomusic,MuChoMusic,music,,,,,,,eng,,https://huggingface.co/datasets/mulab-mir/muchomusic,https://huggingface.co/datasets/mulab-mir/muchomusic,,
multext-j,日本語MULTEXT韻律コーパス (MULTEXT-J),speech,1,16,unknown,w/o,w/o,,jpn,research only,https://research.nii.ac.jp/src/MULTEXT-J.html,https://www.nii.ac.jp/dsc/idr/speech/submit/MULTEXT-J.html,,
musan-mus,MUSAN music,music,1,16,unknown,N/A,N/A,42.5,N/A,CC BY 4.0,https://www.openslr.org/17/,https://www.openslr.org/17/,,
musan-noise,MUSAN audio,audio,1,16,unknown,N/A,N/A,6,N/A,CC BY 4.0,https://www.openslr.org/17/,https://www.openslr.org/17/,,
musan-sp,MUSAN speech,speech,1,16,unknown,N/A,N/A,60,"eng, others",CC BY 4.0,https://www.openslr.org/17/,https://www.openslr.org/17/,,
musdb18,MUSDB18: a dataset of 150 full lengths music tracks,"music, speech",2,44.1,yes,N/A,N/A,10,N/A,various,https://zenodo.org/records/1117372,https://zenodo.org/records/1117372,,
music4all,Music4all,music,,,,w/,w/,900,N/A,research only?,https://sites.google.com/view/contact4music4all,https://sites.google.com/view/contact4music4all,,
musicbench,MusicBench,music,,,,w/,w/,,eng,CC BY-SA 3.0,https://huggingface.co/datasets/amaai-lab/MusicBench,https://huggingface.co/datasets/amaai-lab/MusicBench,,
musiccaps,MusicCaps,music,2,44.1,yes,w/,w/,15,eng,CC BY-SA 4.0,https://huggingface.co/datasets/google/MusicCaps,https://huggingface.co/datasets/google/MusicCaps,,
musicinstruct,MusicInstruct,music,2,44.1,yes,w/,w/,15,eng,CC BY-NC 4.0,https://huggingface.co/datasets/m-a-p/Music-Instruct,https://huggingface.co/datasets/m-a-p/Music-Instruct,,
musicnet,MusicNet,music,1,44.1,unknown,N/A,N/A,34,eng,CC BY 4.0,https://www.kaggle.com/datasets/imsparsh/musicnet-dataset,https://www.kaggle.com/datasets/imsparsh/musicnet-dataset,,
musicqa,MusicQA,music,others,others,unknown,N/A,N/A,0,eng,none,https://huggingface.co/datasets/mu-llama/MusicQA,https://huggingface.co/datasets/mu-llama/MusicQA,,
mvsep-guitar,MVSEP guitar dataset,music,2,44.1,no,w/,w/,0.5,N/A,none,https://mvsep.com/quality_checker/custom_leaderboards,https://mvsep.com/storage/public/guitar_validation.zip,,
mvsep-medleyvox,Medley Vox dataset,music,1,44.1,no,w/,w/,1,N/A,none,https://mvsep.com/quality_checker/custom_leaderboards,https://mvsep.com/storage/public/medley_vox_mixtures.zip,,
mvsep-multi,MVSEP multisong dataset,music,2,44.1,no,w/,w/,1.6,"eng, others",none,https://mvsep.com/ja/quality_checker,https://mvsep.com/storage/public/multisong_dataset.zip,,
mvsep-piano,MVSEP piano dataset,music,2,44.1,no,w/,w/,0.9,N/A,none,https://mvsep.com/quality_checker/custom_leaderboards,https://mvsep.com/storage/public/piano_mixtures.zip,,
mvsep-strings,MVSEP strings dataset,music,2,44.1,no,w/,w/,0.5,N/A,none,https://mvsep.com/quality_checker/custom_leaderboards,https://mvsep.com/storage/public/strings_mixtures.zip,,
mvsep-synth,MVSEP synthesic dataset,music,2,44.1,no,w/,w/,1.6,N/A,none,https://mvsep.com/ja/quality_checker,https://mvsep.com/storage/public/synth_dataset.zip,,
mvsep-wind,MVSEP wind dataset,music,2,44.1,no,w/,w/,0.6,N/A,none,https://mvsep.com/quality_checker/custom_leaderboards,https://mvsep.com/storage/public/wind_mixtures.zip,,
myriad,MYRiAD: A Multi-Array Room Acoustic Database,audio,3+,44.1,no,w/,w/,75,N/A,CC BY-NC-SA 4.0,https://zenodo.org/records/7389996,https://zenodo.org/records/7389996,,
naist-sic-2022,NAIST-SIC 2022: NAIST Simultaneous Interpretation Corpus 2022,speech,1,,,w/o,w/o,300,"eng, jpn",research only,https://dsc-nlp.naist.jp/data/NAIST-SIC/2022/,https://dsc-nlp.naist.jp/data/NAIST-SIC/2022/,,
nhss,NHSS: A Speech and Singing Parallel Database,speech,1,48+,no,w/o,w/o,7,eng,research only,https://hltnus.github.io/NHSSDatabase/index.html,https://hltnus.github.io/NHSSDatabase/download.html,,
ninjal-btsj1000,BTSJ Japanese 1000 Person Natural Conversation Corpus,speech,2,32,yes,w/,w/,130,jpn,research only,https://mmsrv.ninjal.ac.jp/btsj/,https://mmsrv.ninjal.ac.jp/btsj/corpus.html,,
ninjal-bunkacho,Emergency Survey of Regional Dialects,speech,2,48+,no,w/,w/,30,jpn,none,https://kikigengo.ninjal.ac.jp/kinkyu/,https://kikigengo.ninjal.ac.jp/kinkyu/,,
ninjal-dejd,Database of Endangered Languages of Japan,speech,1,16,yes,w/,w/,1.2,jpn,none,https://kikigengo.ninjal.ac.jp/,https://kikigengo.ninjal.ac.jp/data/danwa/search,,
ninjal-hougendanwa,Texts of Tape-Recorded Conversations in Japanese Dialects,speech,1,16,yes,w/,w/,55,jpn,CC BY 4.0,https://mmsrv.ninjal.ac.jp/hogendanwa_siryo/,https://mmsrv.ninjal.ac.jp/hogendanwa_siryo/,,
ninjal-hougensiryou,Dialect Recordings Series,speech,2,16,yes,w/,w/,15,jpn,"public domain, CC BY 4.0",https://mmsrv.ninjal.ac.jp/hogenrokuon_siryo/,https://mmsrv.ninjal.ac.jp/hogenrokuon_siryo/,,
ninjal-nihongolearner,Japanese Language Learner Conversation Database,speech,2,44.1,yes,w/,w/,100,jpn,CC BY-NC-ND 4.0,https://mmsrv.ninjal.ac.jp/kaiwa/,https://mmsrv.ninjal.ac.jp/kaiwa/,,
nisqa,NISQA: Speech Quality and Naturalness Assessment,speech,1,48+,no,w/o,w/o,25,eng,"https://github.com/gabrielmittag/NISQA/wiki/NISQA-Corpus, (ok for commercial use)",https://github.com/gabrielmittag/NISQA,https://github.com/gabrielmittag/NISQA?tab=readme-ov-file#nisqa-corpus,,
nonspeech7k,Nonspeech7k dataset,speech,1,32,yes,w/,w/,2,N/A,CC BY-NC-SA 4.0,https://zenodo.org/records/6967442,https://zenodo.org/records/6967442,,
nsynth,NSynth,music,1,16,no,w/o,w/o,340,eng,CC BY 4.0,https://magenta.tensorflow.org/datasets/nsynth,https://magenta.tensorflow.org/datasets/nsynth#files,,
number7-sing,No.7 singing voice dataset ,speech,1,48+,no,w/o,w/o,1,jpn,research only,https://voiceseven.com/,https://voiceseven.com/,,
number7-speech,No.7 speech dataset ,speech,1,48+,no,w/o,w/o,20,jpn,research only,https://voiceseven.com/,https://voiceseven.com/,,
nus-48e,NUS-48E: NUS Sung and Spoken Lyrics Corpus,speech,1,44.1,no,w/o,w/o,3,eng,none,https://opendatalab.com/OpenDataLab/NUS-48E,https://drive.google.com/drive/folders/12pP9uUl0HTVANU3IPLnumTJiRjPtVUMx,,
ogvc,感情評定値付きオンラインゲーム音声チャットコーパス (OGVC),speech,1,"44.1, 48+",unknown,w/o,w/,13.5,jpn,research only,https://research.nii.ac.jp/src/OGVC.html,https://www.nii.ac.jp/dsc/idr/speech/submit/OGVC.html,,
ojama-song,OJaMa: Speech Corpus of an Ordinary Japanese Male Speaker,speech,1,48+,no,w/o,w/o,2,jpn,research only,https://sython.org/Corpus/OJaMa-Song/,https://sython.org/Corpus/OJaMa-Song/,,
oogami,宮古大神島方言音声データベース (Oogami),speech,2,44.1,unknown,w/,w/,,jpn,research only,https://research.nii.ac.jp/src/Oogami.html,https://www.nii.ac.jp/dsc/idr/speech/submit/Oogami.html,,
openair-ao,Openair anechoic-orchestra,music,2,44.1,unknown,both,w/o,0.5,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/anechoic-orchestra/Anechoic%20Orchestral/,,
openair-apb,Openair acoustics-and-psychoacoustics-book,"music, speech",1,44.1,unknown,w/o,w/o,0.05,eng,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/acoustics-and-psychoacoustics-book/mono/,,
openair-bb,Openair baroque-bassoon,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/baroque-bassoon/mono/,,
openair-bsv,Openair bass-viol,music,1,44.1,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/bicycle-horn/mono/,,
openair-burp,Openair burping 1 and 2,audio,1,44.1,unknown,w/o,w/o,0.01,others,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/burping%201/,,
openair-bv,Openair baroque-viola,music,1,48+,unknown,w/o,w/o,0.05,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/baroque-viola/mono/,,
openair-bvbm,Openair bass-viol-back-mic,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,"""https://webfiles.york.ac.uk/OPENAIR/Anechoic/bass-viol-back-mic/mono/, https://webfiles.york.ac.uk/OPENAIR/Anechoic/bass-viol/mono/""",,
openair-cb,Openair classical-bassoon,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/classical-bassoon/mono/,,
openair-ccbb,Openair classical-clarinet-bb and c,music,1,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,"""https://webfiles.york.ac.uk/OPENAIR/Anechoic/classical-clarinet-bb/mono/,https://webfiles.york.ac.uk/OPENAIR/Anechoic/classical-clarinet-c/mono/""",,
openair-ht,Openair handel-trumpet,music,1,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/handel-trumpet/mono/,,
openair-mcbb,Openair modern-clarinet-bb,music,1,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/modern-clarinet-bb/mono/,,
openair-mpt,Openair modern-piccolo-trumpet,music,1,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/modern-piccolo-trumpet/mono/,,
openair-mv,Openair modern-viola,music,2,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/modern-viola/mono/,,
openair-nbt,Openair natural-baroque-trumpet,music,1,48+,unknown,w/o,w/o,0.01,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/natural-baroque-trumpet/mono/,,
openair-ov,Openair operatic-voice,speech,1,48+,unknown,w/o,w/o,0,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/operatic-voice/mono/,,
openair-ppc,Openair pocket-preachers-cornet,music,1,48+,unknown,w/o,w/o,0,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/pocket-preachers-cornet/mono/,,
openair-ptvp,Openair piece-three-viols-presented-three-solo-tracks-mulitracking,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,"""https://webfiles.york.ac.uk/OPENAIR/Anechoic/piece-three-viols-presented-three-solo-tracks-mulitracking/mono/, https://webfiles.york.ac.uk/OPENAIR/Anechoic/piece-three-viols-presented-three-solo-tracks-mulitracking-back-mic/mono/""",,
openair-rcbb,Openair romantic-clarinet-bb,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/romantic-clarinet-bb/mono/,,
openair-sp,Openair starter-pistol,audio,1,48+,unknown,w/o,w/o,0,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,https://webfiles.york.ac.uk/OPENAIR/Anechoic/starter-pistol/mono/,,
openair-tnv,Openair tenor-viol,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,"""https://webfiles.york.ac.uk/OPENAIR/Anechoic/tenor-viol/mono/, https://webfiles.york.ac.uk/OPENAIR/Anechoic/tenor-viol-back-microphone/mono/""",,
openair-trv,Openair treble-viol,music,1,48+,unknown,w/o,w/o,0.1,N/A,CC BY 4.0,https://www.openair.hosted.york.ac.uk/?page_id=2,"""https://webfiles.york.ac.uk/OPENAIR/Anechoic/treble-viol/mono/, https://webfiles.york.ac.uk/OPENAIR/Anechoic/treble-viol-back-microphone/mono/""",,
openaqa,OpenAQA dataset,audio,1,16,yes,w/,w/,0,eng,none,https://github.com/YuanGongND/ltu?tab=readme-ov-file#openaqa-ltu-and-openasqa-ltu-as-dataset,https://github.com/YuanGongND/ltu?tab=readme-ov-file#openaqa-ltu-and-openasqa-ltu-as-dataset,,
openasqa,OpenASQA dataset,audio,1,16,yes,w/,w/,0,eng,none,https://github.com/YuanGongND/ltu?tab=readme-ov-file#openaqa-ltu-and-openasqa-ltu-as-dataset,https://github.com/YuanGongND/ltu?tab=readme-ov-file#openaqa-ltu-and-openasqa-ltu-as-dataset,,
opencpop,Opencpop,speech,2,44.1,yes,w/o,w/o,5.2,cmn,CC BY-NC-ND 4.0,https://wenet.org.cn/opencpop/,https://wenet.org.cn/opencpop/download/,,
openmic-2018,"OpenMIC-2018: instrument recognition dataset containing 20,000 examples of Creative Commons-licensed music available on the Free Music Archive",music,2,44.1,yes,w/,w/,55,N/A,CC BY 4.0,https://github.com/cosmir/openmic-2018,https://zenodo.org/records/1432913#.W6dPeJNKjOR,,
pasd,"Priority Areas ""Spoken Dialogue"" Simulated Spoken Dialogue Corpus (PASD)",speech,1,16,no,w/,w/,7.5,jpn,research only,https://research.nii.ac.jp/src/PASD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/PASD.html,,
pasl-dsr,PASL-DSR,speech,1,16,no,w/o,w/o,3,jpn,research only,https://research.nii.ac.jp/src/PASL-DSR.html,https://www.nii.ac.jp/dsc/idr/speech/submit/PASL-DSR.html,,
pcd,Piano Concerto Dataset,music,2,22.05,no,w/o,w/,2,N/A,none,https://www.audiolabs-erlangen.de/resources/MIR/PCD,https://www.audiolabs-erlangen.de/resources/MIR/PCD,,
people-speech,The People's Speech Dataset is among the world's largest English speech recognition corpus,speech,1,16,yes,w/,w/,30000,eng,CC BY 4.0,https://huggingface.co/datasets/MLCommons/peoples_speech,https://huggingface.co/datasets/MLCommons/peoples_speech,,
phonation,Phonation,speech,1,44.1,no,w/o,w/o,0.2,N/A,CC BY-NC-SA 4.0,https://osf.io/pa3ha/,https://osf.io/pa3ha/,,
pitch-estimation,Speech and Noise Corpora for Pitch Estimation of Human Speech,"speech, audio",1,"16, 48+",,w/,w/,,eng,non-commercial,https://zenodo.org/records/3921794,https://zenodo.org/records/3921794,,
pjs,PJS: Phoneme-balanced Japanese Singing-voice corpus,speech,1,48+,no,w/o,w/o,0.45,jpn,CC BY-SA 4.0,https://sites.google.com/site/shinnosuketakamichi/research-topics/pjs_corpus,https://drive.google.com/file/d/1hPHwOkSe2Vnq6hXrhVtzNskJjVMQmvN_/view?usp=sharing,,
primewords-1,Primewords Chinese Corpus Set 1,speech,,,yes,w/,w/,100,cmn,CC BY-NC-ND 4.0,https://www.openslr.org/47/,https://www.openslr.org/47/,,
quesst-2014,QUESST 2014: Multilingual Database for Query-by-Example Keyword Spotting,speech,1,8,no,w/,w/,23,"eng, others",none,https://speech.fit.vut.cz/software/quesst-2014-multilingual-database-query-by-example-keyword-spotting,https://speech.fit.vut.cz/software/quesst-2014-multilingual-database-query-by-example-keyword-spotting,,
qut-noise,QUT NOISE,audio,2,48+,no,w/,w/o,20,N/A,CC BY-SA 4.0,https://eprints.qut.edu.au/38144/,https://github.com/qutsaivt/QUT-NOISE?tab=readme-ov-file,,
ravdess,The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),speech,1,48+,no,w/o,w/o,1.5,eng,CC BY-NC-SA 4.0,https://zenodo.org/records/1188976,https://zenodo.org/records/1188976,,
realman-noise,A Real-Recorded and Annotated Microphone Array Dataset for Dynamic Speech Enhancement and Localization,audio,3+,48+,no,w/o,w/,144.5,others,CC BY 4.0,https://github.com/Audio-WestlakeU/RealMAN,https://huggingface.co/datasets/AISHELL/RealMAN,,
realman-sp,A Real-Recorded and Annotated Microphone Array Dataset for Dynamic Speech Enhancement and Localization,speech,3+,48+,no,w/o,w/,83.7,others,CC BY 4.0,https://github.com/Audio-WestlakeU/RealMAN,https://huggingface.co/datasets/AISHELL/RealMAN,,
realvad,RealVAD: A Real-world Dataset for Voice Activity Detection,speech,,,,w/,w/,1.4,,CC BY 4.0,https://zenodo.org/records/3928151,https://zenodo.org/records/3928151,,
reasonspeech,ReasonSpeech,speech,1,16,yes,w/,w/,19000,jpn,CDLA-Sharing-1.0,https://research.reazon.jp/projects/ReazonSpeech/index.html,https://huggingface.co/datasets/reazon-research/reazonspeech,,
reverb,REVERB (REverberant Voice Enhancement and Recognition Benchmark) challenge,speech,"1, 2, 3+",16,no,20 or w/,200-800,,eng,non-commercial,https://reverb2014.audiolabs-erlangen.de/,https://reverb2014.audiolabs-erlangen.de/download.html,,
rfcx,Rainforest Connection Species Audio Detection,audio,1,48+,no,w/,w/,,N/A,https://www.kaggle.com/competitions/rfcx-species-audio-detection/rules,https://www.kaggle.com/competitions/rfcx-species-audio-detection,https://www.kaggle.com/competitions/rfcx-species-audio-detection,,
risc,RISC: RItsumeikan Shout Corpus,speech,1,48+,no,w/o,w/o,1.5,jpn,,https://t-fukumori.net/corpus/RISC/en.html,https://t-fukumori.net/corpus/RISC/en.html,,
rohan,ROHAN: A mora-balanced Japanese text corpus for text-to-speech synthesis,speech,1,48+,no,w/o,w/o,6,jpn,research only,https://github.com/mmorise/rohan4600,https://zunko.jp/multimodal_dev/login.php,,
rtmridb-v1,rtMRIDB v1: Real-Time MRI Articulatory Databases,speech,1,44.1,yes,w/o,w/o,7,jpn,research only,https://research.nii.ac.jp/src/rtMRIDB.html,https://research.nii.ac.jp/src/rtMRIDB.html,,
rtmridb-v2,rtMRIDB v2: Real-Time MRI Articulatory Databases,speech,1,44.1,yes,w/o,w/o,10,jpn,CC BY-NC-SA 4.0,https://www.nii.ac.jp/news/2022/0922.html,https://rtmridb.ninjal.ac.jp/,,
rwc-mus,RWC (Real World Computing) Music Database,music,2,44.1,no,"w, w/o","w, w/o",23.7,jpn,research only,https://staff.aist.go.jp/m.goto/RWC-MDB/index-j.html,https://staff.aist.go.jp/m.goto/RWC-MDB/index-j.html,,
rwcp-sp01,RWCP 会議音声データベース,speech,1,16,no,w/,w/,,jpn,research only,https://research.nii.ac.jp/src/RWCP-SP01.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SP01.html,,
rwcp-sp96,RWCP 音声対話データベース - 96年版,speech,2,16,no,w/,w/,,jpn,research only,https://research.nii.ac.jp/src/RWCP-SP96.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SP96.html,,
rwcp-sp97,RWCP 音声対話データベース - 97年版,speech,2,16,no,w/,w/,,jpn,research only,https://research.nii.ac.jp/src/RWCP-SP97.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SP97.html,,
rwcp-sp99,RWCP 検索・要約用ニュース音声データベース,speech,1,16,no,w/o,w/o,,jpn,research only,https://research.nii.ac.jp/src/RWCP-SP99.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SP99.html,,
rwcp-ssd-1,RWCP 実環境音声・音響データベース 非音声音ドライソース,audio,1,48+,no,w/o,w/o,,N/A,research only,https://research.nii.ac.jp/src/RWCP-SSD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SSD.html,,
rwcp-ssd-2,RWCP 実環境音声・音響データベース マイクロホンアレーデータベース,"speech, others",3+,48+,,w/,w/,,"jpn, eng",research only,https://research.nii.ac.jp/src/RWCP-SSD.html,https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SSD.html,,
saraga,Saraga collection: the largest annotated open data collections available for computational research on Indian Art Music,music,"2, 3+",44.1,yes,N/A,N/A,100,N/A,CC BY-NC 4.0,https://mtg.github.io/saraga/,https://mtg.github.io/saraga/,,
sassec,Stereo Audio Source Separation Evaluation Campaign,"speech, music",2,16,no,N/A,250,0.3,N/A,CC BY-NC-SA 2.0,https://www.irisa.fr/metiss/SASSEC07/,https://www.irisa.fr/metiss/SASSEC07/,,
savee,Surrey Audio-Visual Expressed Emotion (SAVEE): A dataset for training emotion (7 cardinal emotions) classification in audio,speech,1,44.1,no,w/o,w/,0.5,eng,research only,http://kahlan.eps.surrey.ac.uk/savee/,http://kahlan.eps.surrey.ac.uk/savee/Download.html,,
SBCSAE,The Santa Barbara Corpus of Spoken American English,speech,2,22.05,no,w/,w/,20,eng,CC BY-ND 3.0,https://www.openslr.org/155/,https://www.openslr.org/155/,,
scenefake,SceneFake,speech,1,16,no,w/,w/,30,eng,CC BY-NC-ND 4.0,http://addchallenge.cn/databases2023,https://zenodo.org/records/7663324,,
schubert_winter,Schubert Winterreise Dataset,music,1,22.05,no,w/,w/,2,N/A,CC BY 3.0,https://zenodo.org/records/10839767,https://zenodo.org/records/10839767/files/Schubert_Winterreise_Dataset_v2-1.zip?download=1,,
sdxdb23_labelnoise,SDXDB23_LabelNoise,music,2,44.1,no,w/,w/,,N/A,unknown,https://music.ai/research/#datasets,https://music.ai/research/#datasets,,
sebass-db,Subjective Evaluation of Blind Audio Source Separation Database: SEBASS-DB,music,2,48+,no,w/,w/,,N/A,CC BY-NC-SA 4.0,https://www.audiolabs-erlangen.de/resources/2019-WASPAA-SEBASS,https://www.audiolabs-erlangen.de/resources/2019-WASPAA-SEBASS,,
singstyle111,SingStyle111: A Multilingual Singing Dataset With Style Transfer,speech,1,24,no,w/o,w/o,13,"eng, cmn, others",non-commercial,https://dsqvival.github.io/singstyle111/,https://dsqvival.github.io/singstyle111/,,
sisec2008-d1,2008 Signal Separation Evaluation Campaign -- D1 Under-determined speech and music mixtures,"speech, music",2,16,no,N/A,130 or 250,0.1,"eng, jpn",CC BY-NC-SA 2.0,http://sisec2008.wiki.irisa.fr/tiki-index.php,http://sisec2008.wiki.irisa.fr/tiki-index026a.html?page=Under-determined+speech+and+music+mixtures,,
sisec2008-d2,2008 Signal Separation Evaluation Campaign -- D2 Determined and over-determined speech and music mixtures,"speech, music","3+, 2",16,no,N/A,w/,0.06,"eng, jpn",research only,http://sisec2008.wiki.irisa.fr/tiki-index.php,http://sisec2008.wiki.irisa.fr/tiki-indexbca3.html?page=Determined+and+over-determined+speech+and+music+mixtures,,
sisec2008-d3,2008 Signal Separation Evaluation Campaign -- D3 Head-geometry mixtures of two speech sources in real environments,speech,2,16,no,N/A,w/,1.8,"eng, jpn",CC BY-NC-SA 2.0,http://sisec2008.wiki.irisa.fr/tiki-index.php,http://sisec2008.wiki.irisa.fr/tiki-index98f2.html?page=Head-geometry+mixtures+of+two+speech+sources+in+real+environments%2C+impinging+from+many+directions,,
sisec2008-d4,2008 Signal Separation Evaluation Campaign -- D4 Professionally produced music recordings,music,2,44.1,no,N/A,N/A,0.0075,N/A,unknown,http://sisec2008.wiki.irisa.fr/tiki-index.php,http://sisec2008.wiki.irisa.fr/tiki-index165d.html?page=Professionally+produced+music+recordings,,
sisec2010-d1,2010 Signal Separation Evaluation Campaign -- D1 Under-determined speech and music mixtures,"speech, music",2,16,no,N/A,130 or 380,1,N/A,CC BY-NC-SA 2.0,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-index8f77.html?page=Underdetermined-+speech+and+music+mixtures,,
sisec2010-d2-1,2010 Signal Separation Evaluation Campaign -- D2-1 Determined and over-determined speech and music mixtures,"speech, music","2, 3+",16,no,N/A,450-500,,N/A,,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-indexbca3.html?page=Determined+and+over-determined+speech+and+music+mixtures,,
sisec2010-d2-2,2010 Signal Separation Evaluation Campaign -- D2-2 Robust blind linear/non-linear separation of short two-source-two-microphone recordings,"speech, audio",2,16,no,N/A,N/A,0.01,N/A,research only,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-index7f57.html?page=Robust+blind+linear+separation+of+short+two-sources-two-microphones+recordings,,
sisec2010-d2-3,2010 Signal Separation Evaluation Campaign -- D2-3 Overdetermined speech and music mixtures for human-robot interaction,"speech, music",3+,16,no,N/A,N/A,,N/A,research only,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-indexe056.html?page=Overdetermined+speech+and+music+mixtures+for+human-robot+interaction,,
sisec2010-d2-4,2010 Signal Separation Evaluation Campaign -- D2-4 Determined convolutive mixtures under dynamic conditions,"speech, music",2,16,no,N/A,700-800,0.1,N/A,research only,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-indexce13.html?page=Determined+convolutive+mixtures+under+dynamic+conditions,,
sisec2010-d3,2010 Signal Separation Evaluation Campaign -- D3 Professionally produced music recordings,music,2,44.1,no,N/A,N/A,,N/A,CC (various),http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-index165d.html?page=Professionally+produced+music+recordings,,
sisec2010-d4,2010 Signal Separation Evaluation Campaign -- D4 Source separation in the presence of real-world background noise,speech,"2, 3+",16,no,w/,N/A,,N/A,CC BY-NC-SA 3.0,http://sisec2010.wiki.irisa.fr/tiki-index.php,http://sisec2010.wiki.irisa.fr/tiki-indexa8a1.html?page=Source+separation+in+the+presence+of+real-world+background+noise,,
sisec2011-d1,2011 Signal Separation Evaluation Campaign -- D1 Under-determined speech and music mixtures,"speech, music","2, 3+",16,no,N/A,130 or 250 or 380,,N/A,CC BY-NC-SA 2.0,http://sisec2011.wiki.irisa.fr/tiki-index.php,http://sisec2011.wiki.irisa.fr/tiki-indexbfd7.html?page=Underdetermined+speech+and+music+mixtures,,
sisec2011-d2,2011 Signal Separation Evaluation Campaign -- D2 Determined convolutive mixtures under dynamic conditions,speech,3+,16,no,N/A,700,,N/A,,http://sisec2011.wiki.irisa.fr/tiki-index.php,http://sisec2011.wiki.irisa.fr/tiki-indexce13.html?page=Determined+convolutive+mixtures+under+dynamic+conditions,,
sisec2011-d3,2011 Signal Separation Evaluation Campaign -- D3 Professionally produced music recordings,music,2,44.1,no,N/A,N/A,,N/A,CC (various),http://sisec2011.wiki.irisa.fr/tiki-index.php,http://sisec2011.wiki.irisa.fr/tiki-index165d.html?page=Professionally+produced+music+recordings,,
sisec2011-d4,2011 Signal Separation Evaluation Campaign -- D4 Two-channel mixtures of speech and real-world background noise,"speech, audio",2,16,no,w/,N/A,,N/A,CC BY-NC-SA 3.0,http://sisec2011.wiki.irisa.fr/tiki-index.php,http://sisec2011.wiki.irisa.fr/tiki-index79f3.html?page=Two-channel+mixtures+of+speech+and+real-world+background+noise,,
sisec2013-d3,2013 Signal Separation Evaluation Campaign -- D3 Professionally produced music recordings,music,2,44.1,no,N/A,N/A,,N/A,CC (various),http://sisec.wiki.irisa.fr/tiki-index.html,http://sisec.wiki.irisa.fr/tiki-index165d.html?page=Professionally+produced+music+recordings,,
sisec2013-d4,2013 Signal Separation Evaluation Campaign -- D4 Two-channel noisy recordings of a moving speaker within a limited area,"speech, audio",2,"16, 44.1",no,w/,N/A,,N/A,CC BY-NC-SA 3.0,http://sisec.wiki.irisa.fr/tiki-index.html,http://sisec.wiki.irisa.fr/tiki-index98cf.html?page=Two-channel+noisy+recordings+of+a+moving+speaker+within+a+limited+area,,
sisec2013-d5,2013 Signal Separation Evaluation Campaign -- D5 Asynchronous recordings of speech mixtures,"speech, audio",2,"16, others",no,N/A,150 or 300,,N/A,CC BY-NC-SA 3.0,http://sisec.wiki.irisa.fr/tiki-index.html,http://sisec.wiki.irisa.fr/tiki-indexb74c.html?page=Asynchronous+recordings+of+speech+mixtures,,
sisec2015-d4,2015 Signal Separation Evaluation Campaign -- D4 Asynchronous recordings of speech mixtures,"speech, audio",2,"16, others",no,N/A,150 or 300 or 800,,N/A,CC BY-NC-SA 3.0,https://sisec.inria.fr/sisec-2015/,https://sisec.inria.fr/sisec-2015/2015-asynchronous-recordings-of-speech-mixtures/,,
slakh2100,slakh2100: a dataset of multi-track audio and aligned MIDI for music source separation and multi-instrument automatic transcription,music,1,44.1,no,w/o,w/o,145,N/A,CC BY 4.0,http://www.slakh.com/,https://zenodo.org/records/4599666,,
slidespeech,"SlideSpeech: A Large-scale English Multi-Modal Audio-Visual Corpus, provided by Alibaba Group",speech,1,16,yes,w/,w/o,1000,eng,CC BY-SA 4.0,https://www.openslr.org/144/,https://www.openslr.org/144/,,
slurp,SLURP: A Spoken Language Understanding Resource Package,speech,,,,w/,w/o,58,eng,CC BY-NC 4.0,https://zenodo.org/records/4274930,https://zenodo.org/records/4274930,,
smard,SMARD: estimating impulse reponses between all loudspeaker-microphone pairs,"speech, music, others",others,48+,no,w/o,150,4,eng,"If you choose to use parts of the recordings from our database for your research or any other purpose, we would kindly ask you to cite our work by citing our IWAENC2014 paper:",https://www.smard.es.aau.dk/,https://www.smard.es.aau.dk/downloads/,,
smiip-tv,SMIIP-TV dataset: A short-term time-varying speaker verificaition dataset,speech,1,16,yes,w/,w/,300,cmn,CC BY-SA 3.0,https://www.openslr.org/156/,https://www.openslr.org/156/,,
somos-v2,SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis,speech,1,24,no,w/o,w/o,30,eng,CC BY-NC 4.0,https://zenodo.org/records/7378801,https://zenodo.org/records/7378801,,
songdiscriber,Song Discriber Dataset,music,2,44.1,yes,w/,w/,,eng,CC BY-SA 4.0,https://zenodo.org/records/10072001,https://zenodo.org/records/10072001,,
sonyc-ust-v2.3.0,SONYC Urban Sound Tagging (SONYC-UST): dataset for the development and evaluation of machine listening systems for realistic urban noise monitoring,"audio, music, speech",1,48+,no,w/,w/,50,N/A,CC BY 4.0,https://zenodo.org/records/3966543,https://zenodo.org/records/3966543,,
sound-vecaps,Sound-VECaps,audio,1,48+,yes,w/,w/,16000,eng,CC BY 4.0,https://github.com/yyua8222/Sound-VECaps,https://zenodo.org/records/12606207,,
sounddescs,SoundDescs: Audio Retrieval with Natural Language Queries: A Benchmark Study,audio,1,"16, 44.1",yes,N/A,w/,1060,eng,non-commercial,https://github.com/akoepke/audio-retrieval-benchmark,https://github.com/akoepke/audio-retrieval-benchmark,,
spatial-librispeech,Spatial LibriSpeech,speech,3+,16,no,w/,w/,650,eng,CC BY 4.0,https://github.com/apple/ml-spatial-librispeech,https://github.com/apple/ml-spatial-librispeech,,
speech-coco,SPEECH-COCO,speech,1,24,yes,w/o,w/o,600,"eng, jpn",CC BY 4.0,https://zenodo.org/records/4282267,https://zenodo.org/records/4282267,,
speech-command,Speech Commands,speech,1,16,yes,w/,w/,18,eng,CC BY 4.0,https://huggingface.co/datasets/google/speech_commands,https://huggingface.co/datasets/google/speech_commands,,
speech-massive,Speech-MASSIVE,speech,,,yes,w/,w/,80,"eng, others",CC BY-NC-SA 4.0,https://huggingface.co/datasets/FBK-MT/Speech-MASSIVE,https://huggingface.co/datasets/FBK-MT/Speech-MASSIVE,,
speechocean762,speechocean762: Deeply parent-child vocal interaction dataset,speech,1,16,no,"w/, w/o","w/, w/o",282,others,CC BY-NC-ND 4.0,https://www.openslr.org/98/,https://www.openslr.org/98/,,
speechspeed,SpeedSpeech-JA-2022,speech,1,48+,no,w/o,w/o,3,jpn,CC BY-NC 4.0,https://ast-astrec.nict.go.jp/release/speedspeech_ja_2022/download_en.html,https://ast-astrec.nict.go.jp/release/speedspeech_ja_2022/download_en.html,,
spgispeech,SPGISpeech,speech,1,16,yes,w/,w/,5000,eng,https://datasets.kensho.com/datasets/spgispeech,https://datasets.kensho.com/datasets/spgispeech,https://datasets.kensho.com/datasets/spgispeech,,
spoken-coco,Synthetically Spoken COCO,speech,1,24,yes,w/o,w/o,350,eng,CC BY 4.0,https://zenodo.org/records/400926,https://zenodo.org/records/400926,,
src4vc,Smartphone-Recorded Corpus for Voice Conversion,speech,1,"48+, 22.05",no,w/,w/o,11,jpn,research only,https://y-saito.sakura.ne.jp/sython/Corpus/SRC4VC/index.html,https://y-saito.sakura.ne.jp/sython/Corpus/SRC4VC/index.html,,
stcmds,Free ST Chinese Mandarin Corpus,speech,,,no,w/o,w/o,110,cmn,CC BY-NC-ND 4.0,https://openslr.trmal.net/38/,https://openslr.trmal.net/38/,,
stemgmd,StemGMD dataset,music,2,44.1,no,w/o,w/o,1224,N/A,CC BY 4.0,https://zenodo.org/records/7860223,https://zenodo.org/records/7860223,,
studies,STUDIES Corpus: Japanese empathetic dialogue speech corpus,speech,1,48+,no,w/o,w/o,8,jpn,research only,https://sython.org/Corpus/STUDIES/,https://www.nii.ac.jp/dsc/idr/speech/submit/STUDIES.html,,
studiomaestro,StudioMAESTRO dataset,music,1,16,no,w/o,w/o,,N/A,CC BY-NC 4.0,https://zenodo.org/records/10082144,https://zenodo.org/records/10082144,,
supra-rw,SUPRA-RW: 457 MIDI and audio transcriptsion of Red Welte-Mignon piano rolls scanned by the Stanford Libraries' Digital Production Group in 2018 and 2019,music,1,44.1,yes,w/o,w/o,52,N/A,CC BY-NC-SA 4.0,https://supra.stanford.edu/download/,https://purl.stanford.edu/xf457dx9166,,
tau-as,TAU-Urban Acoustic Scenes 2019,audio,2,48+,yes,w/,w/,40,N/A,non-commercial,https://zenodo.org/records/2589280,https://zenodo.org/records/2589280,,
tau-sebin,TAU-SEBin Binaural Sound Events 2021,audio,2,24,no,w/,w/,3,N/A,non-commercial,https://zenodo.org/records/5118587,https://zenodo.org/records/5118587,,
ted-lium-v1,TED-LIUM: English speech recognition training corpus from TED talks,speech,1,16,no,w/,w/,118,eng,CC BY-NC-ND 3.0,https://www.openslr.org/7/,https://www.openslr.org/7/,,
ted-lium-v2,TED-LIUMv2: English speech recognition training corpus from TED talks,speech,1,16,no,w/,w/,207,eng,CC BY-NC-ND 3.0,https://www.openslr.org/19/,https://www.openslr.org/19/,,
tedlium-3,TEDLIUM 3: English speech recognition training corpus from TED talks,speech,1,16,no,w/,w/,452,eng,CC BY-NC-ND 3.0,https://www.openslr.org/51/,https://www.openslr.org/51/,,
tess,TESS: Toronto emotional speech set,speech,1,others,no,w/o,w/o,1.5,eng,CC BY-NC 4.0,https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP2/E8H2MF,https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP2/E8H2MF,,
this-american-life,This american life,speech,,,,,,,eng,,,,,
timit,TIMIT Acoustic-Phonetic Continuous Speech Corpus,speech,1,16,no,N/A,N/A,5,eng,non-commercial,https://catalog.ldc.upenn.edu/LDC93S1,https://catalog.ldc.upenn.edu/LDC93S1,,
tmw,Tohoku University - Matsushita Isolated Word Database,speech,1,24,no,w/,w/,,jpn,non-commercial,https://research.nii.ac.jp/src/TMW.html,https://www.nii.ac.jp/dsc/idr/speech/submit/TMW.html,,
tohoku-folktale,Tohoku folktale corpus,speech,1,16,yes,w/,w/,10,jpn,OK for commercial use,https://sites.google.com/site/shinnosuketakamichi/research-topics/tohoku-dialect_corpus,https://sites.google.com/site/shinnosuketakamichi/research-topics/tohoku-dialect_corpus,,
tonas,TONAS: a dataset of flamenco a cappella sung melodies with corresponding manual transcriptions,music,,,,,,0.6,others,non-commercial,https://zenodo.org/records/1290722,https://zenodo.org/records/1290722,,
torgo,The TORGO Database: Acoustic and articulatory speech from speakers with dysarthria,speech,1,16,no,w/,w/,,eng,non-commercial,https://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html,https://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html,,
toyadmos,ToyADMOS dataset,audio,3+,48+,no,w/,w/,180,N/A,non-commercial,https://zenodo.org/record/3351307#.YlAc2tPP1di,https://zenodo.org/records/3351307#.YlAc2tPP1di,,
toyadmos2,ToyADMOS2: Another dataset of miniature-machine operating sounds for anomalous sound detection under domain shift conditions,audio,"2, 3+",48+,no,w/,w/,200,N/A,non-commercial,https://github.com/nttcslab/ToyADMOS2-dataset?tab=readme-ov-file,https://zenodo.org/records/4580270#.YLniqmb7RzU,,
tsp-speech,TSP Speech Database,speech,2,48+,no,over 40 dB,w/o,3,eng,Simplified BSD,https://www.mmsp.ece.mcgill.ca/Documents/Data//,https://www.mmsp.ece.mcgill.ca/Documents/Data/TSP-Speech-Database/48k.zip,,
tsukuyomi,つくよみちゃんコーパス,speech,1,48+,no,w/o,w/o,1,jpn,OK for commercial use,https://tyc.rei-yumesaki.net/material/corpus/#toc4,https://tyc.rei-yumesaki.net/material/corpus/#toc4,,
tsuruoka91-92,鶴岡調査音声データベース91-92 (Tsuruoka91-92),speech,1,16,unknown,w/,w/,400,jpn,non-commercial,https://research.nii.ac.jp/src/Tsuruoka91-92.html,https://www.nii.ac.jp/dsc/idr/speech/submit/Tsuruoka91-92.html,,
tunebot,Tunebot,,,,,,,,,,https://interactiveaudiolab.github.io/resources/datasets/tunebot.html,https://interactiveaudiolab.github.io/resources/datasets/tunebot.html,,
tut2017,TUT Acoustic Scenes 2017,audio,1,44.1,no,w/,w/,0.9,N/A,non-commercial,https://zenodo.org/records/400515,https://zenodo.org/records/400515,,
tut2018,TUT Urban Acoustic Scenes 2018,audio,"1, 2","44.1, 48+",no,w/,w/,24,N/A,non-commercial,https://zenodo.org/records/1228142,https://zenodo.org/records/1228142,,
ua-speech-high,UA-SPEECH_high-severity,speech,3+,16,no,w/,w/,30,eng,none,https://github.com/ffxiong/uaspeech,https://huggingface.co/datasets/ngdiana/uaspeech_severity_high,,
ua-speech-low,UA-SPEECH_low-severity,speech,3+,16,no,w/,w/,70,eng,none,https://github.com/ffxiong/uaspeech,https://huggingface.co/datasets/ngdiana/uaspeech_severity_low,,
unmixdb,UnmixDB,music,2,44.1,yes,w/o,w/o,60,N/A,CC BY-NC-ND 4.0,https://zenodo.org/records/1422385#.W7R5zxMzYWo,https://zenodo.org/records/1422385#.W7R5zxMzYWo,,
urban-soundscapes,Urban Soundscapes of the World,audio,"2, 3+",48+,no,N/A,N/A,,N/A,CC BY 4.0,https://urban-soundscapes.org/recordings/,https://zenodo.org/records/10106181,,
urmp,University of Rochester Multi-Modal Music Performance (URMP) ,music,,,,,,,,,https://labsites.rochester.edu/air/projects/URMP.html,,,
us8k,UrbanSound8K,audio,1,"44.1, 48+",yes,w/,w/,9,N/A,CC BY-NC 3.0,https://urbansounddataset.weebly.com/urbansound8k.html,https://urbansounddataset.weebly.com/download-urbansound8k.html,,
ut-ml,University of Tsukuba Multilingual Speech Corpus,speech,1,16,no,w/,w/,,"eng, jpn, others",research only,https://research.nii.ac.jp/src/UT-ML.html,https://www.nii.ac.jp/dsc/idr/speech/submit/UT-ML.html,,
uwb-atcc,UWB-ATCC Corpus,speech,1,16,yes,w/,w/,20,eng,CC BY-NC-SA 4.0,https://huggingface.co/datasets/Jzuluaga/uwb_atcc,https://huggingface.co/datasets/Jzuluaga/uwb_atcc,,
vaystadial,Vystadial,speech,1,16,no,w/,w/,60,"eng, others",CC BY-SA 3.0,https://www.openslr.org/6/,https://www.openslr.org/6/,,
vcc2020,Voice Conversion Challenge 2020 database v1.0,speech,1,24,no,w/o,w/o,0.5,"eng, cmn, others",Open Database License,https://zenodo.org/records/4345689,https://zenodo.org/records/4345689,,歌の種類は少なめ
vctk,VCTK: Centre for Speech Technology Voice Cloning Toolkit,speech,1,48+,no,w/o,w/o,44,eng,CC BY 4.0,https://datashare.ed.ac.uk/handle/10283/3443,https://huggingface.co/datasets/CSTR-Edinburgh/vctk,,
vggsound,VGGsound,audio,1,16,yes,w/,w/,560,eng,CC BY 4.0,https://github.com/hche11/VGGSound?tab=readme-ov-file,https://github.com/hche11/VGGSound?tab=readme-ov-file,,
vietnam-celeb,Vietnam-Celeb,speech,1,16,yes,w/,w/,187,others,none,https://github.com/thanhpv2102/Vietnam-Celeb.Interspeech,https://github.com/thanhpv2102/Vietnam-Celeb.Interspeech,,
violin-gestures,Violin Gestures Dataset,music,1,48+,no,w/o,w/,0.5,N/A,CC BY-NC-SA 4.0,https://interactiveaudiolab.github.io/resources/datasets/fine-grained-vis.html,https://gitlab.doc.gold.ac.uk/expressive-musical-gestures/dataset/-/tree/master/violin/Participant-08/Data,,
vocadito-v3,Vocadito dataset v3,music,1,44.1,yes,w/,w/,1,others,CC BY 4.0,https://zenodo.org/records/5578807,https://zenodo.org/records/5578807,,
vocal-imitation,Fine-grained Vocal Imitation Set,"speech, audio",1,"44.1, 48+",no,w/,w/,30,others,CC BY 4.0,https://interactiveaudiolab.github.io/resources/datasets/otomobile.html,https://zenodo.org/records/3538534,,
vocalset-v1.2,VocalSet v1.2: A Singing Voice Dataset,speech,1,44.1,no,w/o,w/o,10.1,"others, eng",CC BY 4.0,https://zenodo.org/records/1442513,https://zenodo.org/records/1442513,,
vocalsketch-v1.1.2,VocalSketch v.1.1.2,"speech, audio",1,44.1,no,w/,w/,,others,free,https://zenodo.org/records/1251982,https://zenodo.org/records/1251982,,
voiced,VOICED Database,speech,1,8,no,w/,w/,0.3,others,Open Data Commons Attribution License v1.0,https://physionet.org/content/voiced/1.0.0/,https://physionet.org/content/voiced/1.0.0/,,
voicemos2022-v2,VoiceMOS Challenge 2022,speech,1,16,no,w/o,w/o,6,eng,none,https://zenodo.org/records/10691660,https://zenodo.org/records/10691660,,
voxceleb1,"VoxCeleb1: 100,000 utterances for 1,251 celebrities",speech,1,16,yes,w/,w/,352,"eng, others",CC BY-SA 4.0,https://mm.kaist.ac.kr/datasets/voxceleb/,https://mm.kaist.ac.kr/datasets/voxceleb/,,
voxceleb2,"VoxCeleb2: 1 million utterances for 6,112 celebrities",speech,1,16,yes,w/,w/,2442,"eng, others",CC BY-SA 4.0,https://mm.kaist.ac.kr/datasets/voxceleb/,https://mm.kaist.ac.kr/datasets/voxceleb/,,
voxconverse,"VoxConverse: audio-visual diarisation dataset consisting of over 50 hours of multispeaker clips of human speech, extracted from YouTube videos",speech,1,16,yes,w/,w/,50,eng,CC BY 4.0,https://mmai.io/datasets/voxconverse/,https://mmai.io/datasets/voxconverse/,,
voxlingua,VoxLingua: ECAPA-TDNN Spoken Language Identification Model,speech,1,16,yes,w/,w/,6628,"eng, jpn, cmn, others",Apache License v2.0,https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa,https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa,,
voxmovies,"VoxMovies: an audio dataset, containing utterances sourced from movies with varying emotion, accents and background noise",speech,1,16,yes,w/,w/,1270,eng,CC BY 4.0,https://mmai.io/datasets/voxmovies/,https://mmai.io/datasets/voxmovies/,,
voxpopuli,"VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation",speech,1,16,yes,w/,w/,400000,"eng, others",CC BY-NC 4.0,https://github.com/facebookresearch/voxpopuli,https://github.com/facebookresearch/voxpopuli,,
voxtube,VoxTube: a multilingual speaker recognition dataset,speech,1,16,yes,w/,w/,4933,"eng, others",CC BY-NC-SA 4.0,https://github.com/IDRnD/VoxTube,https://huggingface.co/datasets/voice-is-cool/voxtube,,
wagnerring,Wagner Ring Dataset,music,2,22.05,no,w/,w/,200,N/A,CC BY 3.0,https://zenodo.org/records/7672157,https://zenodo.org/records/7672157,,
wavcaps,WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research,audio,1,32,yes,w/,w/,14883,eng,academic only,https://github.com/XinhaoMei/WavCaps,https://huggingface.co/datasets/cvssp/WavCaps,,
wavtext5k,WavText5K: Audio Retrieval with WavText5K and CLAP Training,audio,1,44.1,yes,N/A,w/,25,eng,MIT,https://github.com/microsoft/WavText5K,https://github.com/microsoft/WavText5K,,
wearable-SELD,Wearable SELD dataset is a dataset to develop a sound event localization and detection (SELD) system with wearable devices,audio,3+,48+,no,w/,w/,7,N/A,non-commercial,https://github.com/nttrd-mdlab/wearable-seld-dataset/,https://github.com/nttrd-mdlab/wearable-seld-dataset/,,
wenetspeech,WenetSpeech: A 10000+ Hours Multi-domain Chinese Corpus for Speech Recognition,speech,1,16,yes,w/,w/,10000,cmn,research only,https://wenet.org.cn/WenetSpeech/,https://github.com/wenet-e2e/WenetSpeech,,
wenetspeech-tts,"WenetSpeech4TTS: A 12,800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark",speech,1,24,yes,w/,w/,12800,cmn,CC BY 4.0,https://huggingface.co/datasets/Wenetspeech4TTS/WenetSpeech4TTS,https://huggingface.co/datasets/Wenetspeech4TTS/WenetSpeech4TTS,,
wham-48k,WHAM!48kHz noise dataset: Full-length noise recordings at the original sample rate.,audio,2,48+,no,N/A,w/,80,eng,CC BY-NC 4.0,http://wham.whisper.ai/,http://wham.whisper.ai/,,
wikimute,WikiMuTe: A web-sourced dataset of semantic descriptions for music audio,music,1,44.1,yes,w/,w/,202,eng,CC BY-SA 3.0,https://zenodo.org/records/10223363,https://zenodo.org/records/10223363,,
wilddesed-v3,WildDESED v3: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection,audio,1,16,no,w/,w/,20,eng,CC BY 4.0,https://github.com/swagshaw/WildDESED?tab=readme-ov-file,https://zenodo.org/records/14013803,,
wildsvdd,SVDD Challenge 2024: A Singing Voice Deepfake Detection Challenge (WildSVDD Track),speech,1,16,no,w/o,w/o,150,"eng, cmn, others",CC BY 4.0,https://github.com/SVDDChallenge/CtrSVDD2024_Baseline,https://zenodo.org/records/10893604,,
wsj-multi,Multi-Channel WSJ Audio,speech,3+,16,yes,w/o,w/,100,eng,Multi-Channel WSJ Audio,https://catalog.ldc.upenn.edu/LDC2014S03,https://catalog.ldc.upenn.edu/LDC2014S03,,
wsj0-mix,WSJ0-mix,speech,,8,,0-10,N/A,40,eng,,https://www.merl.com/research/highlights/deep-clustering,,,
wtkn,Watkins Marine Mammal Sound Database,audio,1,others,yes,w/,w/,27,"N/A, eng",CC BY 4.0,https://whoicf2.whoi.edu/science/B/whalesounds/index.cfm,https://whoicf2.whoi.edu/science/B/whalesounds/index.cfm,,
yodas,YODAS: YouTube-oriented dataset of audio and speech,speech,1,24,yes,w/,w/,422000,"eng, jpn, cmn, others",CC BY 3.0,https://huggingface.co/datasets/espnet/yodas2,https://huggingface.co/datasets/espnet/yodas2,,
yt8m-musictextclips,YouTube8M-MusicTextClips,music,1,others,yes,w/,w/,11,eng,adove research license,https://zenodo.org/records/8040754,https://zenodo.org/records/8040754,,
zed,Zaion Speech Emotion Diarization,speech,1,16,yes,w/,w/,21,eng,CC BY-NC 4.0,https://github.com/BenoitWang/Speech_Emotion_Diarization?tab=readme-ov-file,https://www.dropbox.com/scl/fi/2s3ro8tmgt1lir77z3hj5/ZED.zip?rlkey=qkizx7t3ozo02xs7k1tlexb1e&e=1&st=9l466c1c&dl=0,,
